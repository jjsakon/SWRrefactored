{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "c8565ce5-e0eb-48c5-b577-fd51581941e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "make sure you read through and understand what getSWRpathInfo is doing\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd; pd.set_option('display.max_columns', 30)\n",
    "import numpy as np\n",
    "from cmlreaders import CMLReader, get_data_index\n",
    "import ptsa\n",
    "import sys\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from pylab import *\n",
    "from copy import copy\n",
    "from scipy import stats\n",
    "plt.rcParams['pdf.fonttype'] = 42; plt.rcParams['ps.fonttype'] = 42 # fix fonts for Illustrator\n",
    "# sys.path.append('/home1/john/SWRrefactored/code/SWR_modules/')\n",
    "sys.path.insert(0, '/home1/john/SWRrefactored/code/SWR_modules/')\n",
    "from SWRmodule import *\n",
    "from general import * #superVstack,findInd,findAinB\n",
    "import csv\n",
    "import os\n",
    "import dill, pickle\n",
    "import mne\n",
    "from copy import copy    \n",
    "from scipy.signal import firwin,filtfilt,kaiserord\n",
    "from ptsa.data.filters import ButterworthFilter, ResampleFilter, MorletWaveletFilter\n",
    "import xarray as xarray\n",
    "from brain_labels import HPC_labels, ENT_labels, PHC_labels, temporal_lobe_labels,\\\n",
    "                        MFG_labels, IFG_labels, nonHPC_MTL_labels, ENTPHC_labels, AMY_labels, ACC_OF_MFC_labels\n",
    "import pingouin as pg\n",
    "\n",
    "################################################################\n",
    "df = get_data_index(\"r1\") # all RAM subjects\n",
    "\n",
    "### CHOOSE HERE\n",
    "exp = 'catFR1' # 'catFR1' #'FR1'\n",
    "selected_period = 'countdown' \n",
    "# working trial periods: # surrounding_recall # encoding # countdown # distractor\n",
    "available_regions = {\n",
    "#     \"ACC_OF_labels\": ACC_OF_MFC_labels,   \n",
    "    \"HPC_labels\": HPC_labels,\n",
    "#     \"ENTPHC_labels\": ENTPHC_labels,\n",
    "#     \"AMY_labels\": AMY_labels\n",
    "}\n",
    "\n",
    "remove_soz_ictal = 0\n",
    "recall_minimum = 2000 #5000 # 2000\n",
    "filter_type = 'hamming'\n",
    "extra = '' #'- ZERO_IRI'\n",
    "\n",
    "save_path = f'/scratch/john/SWRrefactored/patient_info/{exp}/'\n",
    "brain_region_idxs = np.arange(len(available_regions))\n",
    "if selected_period == 'encoding':\n",
    "    recall_type_switch = 10 # no IRI requirements for recalls that is necessary for surrounding_recall\n",
    "elif selected_period == 'surrounding_recall':\n",
    "    recall_type_switch = 0 # 0 for original (remove IRI < recall_minimum), 1 for only those with subsequent, 2 for second recalls only, 3 for isolated recalls\n",
    "else:\n",
    "    recall_type_switch = 10\n",
    "    print('make sure you read through and understand what getSWRpathInfo is doing')\n",
    "################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "2af4e368-7826-42ac-8a81-6b06154289a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_region = HPC_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "ff896db0-d906-4d6c-a7c6-ae14b76ed5ae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n:param [int, str] temp_df_select: \\n    if int, then temp_df_select is used to index a row of temp_df\\n    if str, then must be name of a patient. function iterates through \\n    rows of temp_df until row.subject equals temp_df_select\\n\\n:param str selected_period: encoding, surrounding_recall, or whole_retrieval\\n:param str selected_region: which brain region to generate data for \\n:param str save_path: folder to save data in\\n:param str exp: catFR or FR\\n:param bool testing_mode: if in testing mode, saves data to \"test.p\" \\nso as to not overwrite existing data\\n'"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# def ClusterRunSWRs(row, selected_region,save_path, selected_period, \n",
    "#                    exp, testing_mode=False):\n",
    "\n",
    "'''\n",
    ":param [int, str] temp_df_select: \n",
    "    if int, then temp_df_select is used to index a row of temp_df\n",
    "    if str, then must be name of a patient. function iterates through \n",
    "    rows of temp_df until row.subject equals temp_df_select\n",
    "\n",
    ":param str selected_period: encoding, surrounding_recall, or whole_retrieval\n",
    ":param str selected_region: which brain region to generate data for \n",
    ":param str save_path: folder to save data in\n",
    ":param str exp: catFR or FR\n",
    ":param bool testing_mode: if in testing mode, saves data to \"test.p\" \n",
    "so as to not overwrite existing data\n",
    "'''\n",
    "\n",
    "### PARAMS ###\n",
    "\n",
    "##\n",
    "## NOTE: for looking at individual lags make sure min_recalls is set to 0 or will eliminate trials from low recall lists\n",
    "##\n",
    "\n",
    "save_values = 1\n",
    "\n",
    "# there are three periods this code is set up to look at: periods aligned to recall, the entire retrieval period, and the encoding period\n",
    "  # switch to determine which recalls to look at! (see details below)\n",
    "# (as of 2021 always leave this as 0, since I select for 4/6/etc below)\n",
    "# 0: Original analysis taking only recalls without a recall in 2 s IRI before them\n",
    "# 1: Take these same recalls, but keep only those WITH a recall within 2 s after they occur \n",
    "# 2: test condition where we look at second recalls within IRI ONLY (there is an initial recall in 2 s before current recall)\n",
    "# 3: isolated recalls with no other recalls +/- RECALL_MINIMUM s\n",
    "# 4: only first recall of every retrieval period\n",
    "# 5: take only those recalls that come second in retrieval period within 2 s of first retrieval\n",
    "# 6: take only NOT first recall of every retrieval period\n",
    "# 7: take only NOT first recall AND ISOLATED trials (this should REALLY maximize SWR bump)\n",
    "# 10: same as 0 but with no IRI (mostly just to see number of recalls)\n",
    "remove_soz_ictal = 0 # 0 for nothing, 1 for SOZ, 2 for SOZ+ictal    \n",
    "min_ripple_rate = 0.025 # Hz. # 0.1\n",
    "max_ripple_rate = 1.5 # Hz.\n",
    "max_trial_by_trial_correlation = 0.05 # if ripples correlated more than this remove them\n",
    "max_electrode_by_electrode_correlation = 0.2\n",
    "\n",
    "### semantic/temporal clustering parameters ###\n",
    "min_recalls = 0\n",
    "PCA_ndim = 1 # number of PC dims to use for semantic clustering (Ethan usually found only 1 worked for theta/FC)\n",
    "\n",
    "#     # for parametric run through recall_minimums\n",
    "#         recall_mins = np.arange(800,5100,100) #[800,900,1100,1200,1300,1400]\n",
    "# #     recall_mins = [1600,1700,1800,1900,2100,2200,2300,2400,2500,2600,2700,2800,2900,3000]\n",
    "#     for recall_minimum in recall_mins:\n",
    "\n",
    "# recall params\n",
    "#     recall_minimum = 5000 # for isolated recalls what is minimum time for recall to be considered isolated?\n",
    "IRI = 2000 #5000 # inter-recall interval...remove recalls within this range (keep only first one and remove those after it)\n",
    "retrieval_whole_time = 10000\n",
    "# encoding params\n",
    "encoding_time = 2300 # actual preentation is 1.6 s + 0.75-1.0 s so keep +700 ms so can plot +500 ms\n",
    "pre_encoding_time = -700 # since minimum ISI is 0.75 s let's only plot the 500 ms before word on with a 200 ms buffer\n",
    "# these aren't likely to be changed:\n",
    "desired_sample_rate = 500. # in Hz. This seems like lowerst common denominator recording freq.\n",
    "eeg_buffer = 1000 # buffer to add to either end of IRI when processing eeg #**\n",
    "filter_type = 'hamming' # see local version below for details. 'butter' is removed from cluster version so don't change this    \n",
    "\n",
    "### END PARAMS ###    \n",
    "\n",
    "# get region label\n",
    "if selected_region == HPC_labels:\n",
    "    region_name = 'HPC'\n",
    "elif selected_region == ENT_labels:\n",
    "    region_name = 'ENT'\n",
    "elif selected_region == PHC_labels:\n",
    "    region_name = 'PHC'\n",
    "elif selected_region == temporal_lobe_labels:\n",
    "    region_name = 'TEMPORALLOBE'\n",
    "elif selected_region == MFG_labels:\n",
    "    region_name = 'MFG'\n",
    "elif selected_region == IFG_labels:\n",
    "    region_name = 'IFG'\n",
    "elif selected_region == nonHPC_MTL_labels:\n",
    "    region_name = 'nonHPC_MTL'\n",
    "elif selected_region == ENTPHC_labels:\n",
    "    region_name = 'ENTPHC'\n",
    "elif selected_region == AMY_labels:\n",
    "    region_name = 'AMY'\n",
    "elif selected_region == ACC_OF_MFC_labels:\n",
    "    region_name = 'ACC_OF'\n",
    "\n",
    "if selected_period == 'surrounding_recall':\n",
    "    if IRI == 0:\n",
    "        psth_start = -2000\n",
    "        psth_end = 2000\n",
    "    else:\n",
    "        psth_start = -IRI # only makes sense to look at period <= IRI\n",
    "        psth_end = IRI # how long to grab data after recall\n",
    "elif selected_period == 'whole_retrieval':\n",
    "    psth_start = -IRI # doesn't have to be IRI just 2000 ms is convenient\n",
    "    psth_end = IRI+retrieval_whole_time\n",
    "elif selected_period == 'encoding':\n",
    "    psth_start = pre_encoding_time\n",
    "    psth_end = encoding_time\n",
    "elif selected_period == 'countdown':\n",
    "    psth_start = 0\n",
    "elif selected_period == 'distractor':\n",
    "    psth_start = 0\n",
    "\n",
    "ripple_array = []; fr_array = []; \n",
    "trial_nums = []; \n",
    "elec_names = []; sub_sess_names = []; sub_names = []\n",
    "electrodes_per_session = []\n",
    "total_lists = 0; total_recalls = 0; kept_recalls = 0\n",
    "align_adjust = 0\n",
    "ent_elec_ct = []; sd_regions = []; not_sd_regions = []\n",
    "ripple_ied_accum_ct = []\n",
    "time_add_save = []\n",
    "encoded_word_key_array = []; category_array = []\n",
    "\n",
    "session_ripple_rate_by_elec = []; # for cluster version only since I compare across electrodes for each session\n",
    "\n",
    "list_recall_num_array = []; rectime_array = []; # new ones added 2020-11-24\n",
    "serialpos_array = [] # used to be encoding info but commandeered for surrounding_recalls ~~~\n",
    "recall_position_array = []\n",
    "session_events = pd.DataFrame()\n",
    "\n",
    "trial_by_trial_correlation = []; elec_by_elec_correlation = []\n",
    "elec_ripple_rate_array = []\n",
    "channel_coords = []; electrode_labels = []\n",
    "\n",
    "semantic_clustering_key = []\n",
    "temporal_clustering_key = []\n",
    "semantic_clustering_from_key = []\n",
    "serialpos_lags = []; serialpos_from_lags = []; CRP_lags = []\n",
    "list_trial_nums = []; list_num_key = []\n",
    "list_level_semantic = []; list_level_temporal = []\n",
    "\n",
    "program_ran = 0\n",
    "\n",
    "\n",
    "with open(f'/scratch/john/SWRrefactored/patient_info/temp_dfSWR_encoding_{exp}.p', 'rb') as f: ### change here to avoid overwrite\n",
    "    temp_df = dill.load(f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "9cfd414b-d9bd-409a-aabd-26280cf61da3",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R1302M-0\n",
      "BAD COUNTDOWN\n",
      "0\n",
      "R1320D-1\n",
      "BAD COUNTDOWN\n",
      "0\n",
      "R1332M-1\n",
      "BAD COUNTDOWN\n",
      "0\n",
      "R1390M-0\n",
      "BAD COUNTDOWN\n",
      "250\n",
      "R1390M-1\n",
      "BAD COUNTDOWN\n",
      "2067\n",
      "R1390M-2\n",
      "BAD COUNTDOWN\n",
      "2717\n",
      "R1390M-3\n",
      "BAD COUNTDOWN\n",
      "2784\n",
      "R1401J-2\n",
      "BAD COUNTDOWN\n",
      "35\n",
      "R1414E-0\n",
      "BAD COUNTDOWN\n",
      "17\n",
      "R1441T-0\n",
      "BAD COUNTDOWN\n",
      "132\n",
      "R1457T-0\n",
      "BAD COUNTDOWN\n",
      "616\n",
      "R1495J-4\n",
      "BAD COUNTDOWN\n",
      "399\n",
      "R1526J-0\n",
      "BAD COUNTDOWN\n",
      "3700\n",
      "R1536J-3\n",
      "BAD COUNTDOWN\n",
      "650\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "Unable to find the requested file in any of the expected locations:\n /protocols/r1/subjects/R1696L/experiments/catFR1/sessions/0/behavioral/current_processed/task_events.json\n/data/events/pyFR/R1696L_events.mat",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[122], line 24\u001b[0m\n\u001b[1;32m     13\u001b[0m     reader \u001b[38;5;241m=\u001b[39m CMLReadDFRow(row)\n\u001b[1;32m     15\u001b[0m \u001b[38;5;66;03m#     # get localizations (region info)\u001b[39;00m\n\u001b[1;32m     16\u001b[0m \u001b[38;5;66;03m#     pairs = reader.load('pairs')\u001b[39;00m\n\u001b[1;32m     17\u001b[0m \u001b[38;5;66;03m#     try:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[38;5;66;03m#     tal_struct, bipolar_pairs, mpchans = get_bp_tal_struct(sub, montage=mont, localization=loc)\u001b[39;00m\n\u001b[1;32m     22\u001b[0m \u001b[38;5;66;03m#     elec_regions,atlas_type,pair_number,has_stein_das = get_elec_regions(localizations,pairs) \u001b[39;00m\n\u001b[0;32m---> 24\u001b[0m     evs \u001b[38;5;241m=\u001b[39m reader\u001b[38;5;241m.\u001b[39mload(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtask_events\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     26\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m selected_period \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcountdown\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m     27\u001b[0m \n\u001b[1;32m     28\u001b[0m         \u001b[38;5;66;03m# -------------------------------------------------\u001b[39;00m\n\u001b[1;32m     29\u001b[0m         \u001b[38;5;66;03m# Check if COUNTDOWN_START or COUNTDOWN exist\u001b[39;00m\n\u001b[1;32m     30\u001b[0m         \u001b[38;5;66;03m# -------------------------------------------------\u001b[39;00m\n\u001b[1;32m     31\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCOUNTDOWN_START\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m evs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtype\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mvalues:\n",
      "File \u001b[0;32m~/anaconda3/envs/eeg311/lib/python3.11/site-packages/cmlreaders/cmlreader.py:244\u001b[0m, in \u001b[0;36mCMLReader.load\u001b[0;34m(self, data_type, **kwargs)\u001b[0m\n\u001b[1;32m    237\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprotocol \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39mprotocols:\n\u001b[1;32m    238\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m UnsupportedProtocolError(\n\u001b[1;32m    239\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mData type \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m is not supported under protocol \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[1;32m    240\u001b[0m             data_type, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprotocol\n\u001b[1;32m    241\u001b[0m         )\n\u001b[1;32m    242\u001b[0m     )\n\u001b[0;32m--> 244\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39mload(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/anaconda3/envs/eeg311/lib/python3.11/site-packages/cmlreaders/base_reader.py:196\u001b[0m, in \u001b[0;36mBaseCMLReader.load\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    194\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_load_no_cache()\n\u001b[1;32m    195\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcaching \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmemory\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m--> 196\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_load_from_memory()\n\u001b[1;32m    197\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    198\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInvalid caching type: \u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcaching)\n",
      "File \u001b[0;32m~/anaconda3/envs/eeg311/lib/python3.11/site-packages/cmlreaders/base_reader.py:187\u001b[0m, in \u001b[0;36mBaseCMLReader._load_from_memory\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    185\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Load from disk or in-memory cache.\"\"\"\u001b[39;00m\n\u001b[1;32m    186\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_result \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 187\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_load_no_cache()\n\u001b[1;32m    189\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_result\n",
      "File \u001b[0;32m~/anaconda3/envs/eeg311/lib/python3.11/site-packages/cmlreaders/base_reader.py:182\u001b[0m, in \u001b[0;36mBaseCMLReader._load_no_cache\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    180\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Load stored data without using a cache.\"\"\"\u001b[39;00m\n\u001b[1;32m    181\u001b[0m method_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin([\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mas\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdefault_representation])\n\u001b[0;32m--> 182\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m, method_name)()\n",
      "File \u001b[0;32m~/anaconda3/envs/eeg311/lib/python3.11/site-packages/cmlreaders/readers/readers.py:233\u001b[0m, in \u001b[0;36mEventReader.as_dataframe\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    232\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mas_dataframe\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m--> 233\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfile_path\u001b[38;5;241m.\u001b[39mendswith(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.json\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m    234\u001b[0m         df \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_read_json_events()\n\u001b[1;32m    235\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[0;32m~/anaconda3/envs/eeg311/lib/python3.11/site-packages/cmlreaders/base_reader.py:135\u001b[0m, in \u001b[0;36mBaseCMLReader.file_path\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    127\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_file_path \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata_type \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124meeg\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m    128\u001b[0m     finder \u001b[38;5;241m=\u001b[39m PathFinder(subject\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msubject,\n\u001b[1;32m    129\u001b[0m                         experiment\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperiment,\n\u001b[1;32m    130\u001b[0m                         session\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msession,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    133\u001b[0m                         eeg_basename\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39meeg_basename,\n\u001b[1;32m    134\u001b[0m                         rootdir\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrootdir)\n\u001b[0;32m--> 135\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_file_path \u001b[38;5;241m=\u001b[39m finder\u001b[38;5;241m.\u001b[39mfind(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata_type)\n\u001b[1;32m    136\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_file_path\n",
      "File \u001b[0;32m~/anaconda3/envs/eeg311/lib/python3.11/site-packages/cmlreaders/path_finder.py:132\u001b[0m, in \u001b[0;36mPathFinder.find\u001b[0;34m(self, data_type)\u001b[0m\n\u001b[1;32m    129\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m data_type \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m rhino_paths:\n\u001b[1;32m    130\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m InvalidDataTypeRequest(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnknown data type\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 132\u001b[0m expected_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lookup_file(data_type)\n\u001b[1;32m    134\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m expected_path\n",
      "File \u001b[0;32m~/anaconda3/envs/eeg311/lib/python3.11/site-packages/cmlreaders/path_finder.py:164\u001b[0m, in \u001b[0;36mPathFinder._lookup_file\u001b[0;34m(self, data_type)\u001b[0m\n\u001b[1;32m    161\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m data_type \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mramulator_session_folder\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m    162\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m timestamped_dir\n\u001b[0;32m--> 164\u001b[0m expected_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_find_single_path(paths_to_check,\n\u001b[1;32m    165\u001b[0m                                        protocol\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprotocol,\n\u001b[1;32m    166\u001b[0m                                        subject\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msubject,\n\u001b[1;32m    167\u001b[0m                                        subject_montage\u001b[38;5;241m=\u001b[39msubject_montage,\n\u001b[1;32m    168\u001b[0m                                        timestamped_dir\u001b[38;5;241m=\u001b[39mtimestamped_dir,\n\u001b[1;32m    169\u001b[0m                                        experiment\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperiment,\n\u001b[1;32m    170\u001b[0m                                        session\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msession,\n\u001b[1;32m    171\u001b[0m                                        localization\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlocalization,\n\u001b[1;32m    172\u001b[0m                                        montage\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmontage,\n\u001b[1;32m    173\u001b[0m                                        eeg_basename\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39meeg_basename)\n\u001b[1;32m    174\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m expected_path\n",
      "File \u001b[0;32m~/anaconda3/envs/eeg311/lib/python3.11/site-packages/cmlreaders/path_finder.py:232\u001b[0m, in \u001b[0;36mPathFinder._find_single_path\u001b[0;34m(self, paths, **kwargs)\u001b[0m\n\u001b[1;32m    229\u001b[0m         kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mexperiment\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m experiment[:\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\n\u001b[1;32m    230\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_find_single_path(paths, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m--> 232\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mFileNotFoundError\u001b[39;00m(\n\u001b[1;32m    233\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnable to find the requested file in any of the expected \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    234\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlocations:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\u001b[38;5;124m'\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(checked_paths)))\n\u001b[1;32m    236\u001b[0m \u001b[38;5;66;03m# if len(found_files) > 1:\u001b[39;00m\n\u001b[1;32m    237\u001b[0m \u001b[38;5;66;03m#     msg = (\u001b[39;00m\n\u001b[1;32m    238\u001b[0m \u001b[38;5;66;03m#         \"Multiple files found: {}\".format(\"\\n\".join(found_files)) +\u001b[39;00m\n\u001b[1;32m    239\u001b[0m \u001b[38;5;66;03m#         \" returning the first file found\"\u001b[39;00m\n\u001b[1;32m    240\u001b[0m \u001b[38;5;66;03m#     )\u001b[39;00m\n\u001b[1;32m    241\u001b[0m \u001b[38;5;66;03m#     warnings.warn(msg, MultiplePathsFoundWarning)\u001b[39;00m\n\u001b[1;32m    243\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m found_files[\u001b[38;5;241m0\u001b[39m]\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: Unable to find the requested file in any of the expected locations:\n /protocols/r1/subjects/R1696L/experiments/catFR1/sessions/0/behavioral/current_processed/task_events.json\n/data/events/pyFR/R1696L_events.mat"
     ]
    }
   ],
   "source": [
    "max_sess = len(temp_df)\n",
    "\n",
    "for num in range(0,max_sess):\n",
    "    row = temp_df[num]\n",
    "\n",
    "    sub = row.subject\n",
    "    session = row.session\n",
    "    exp = row.experiment\n",
    "    mont = int(row.montage)\n",
    "    loc = int(row.localization)\n",
    "    sub_sess = f\"{sub}-{session}\"  # for convenience\n",
    "\n",
    "    reader = CMLReadDFRow(row)\n",
    "    \n",
    "    # get localizations (region info)\n",
    "    pairs = reader.load('pairs')\n",
    "    try:\n",
    "        localizations = reader.load('localization')\n",
    "    except:\n",
    "        localizations = []\n",
    "    tal_struct, bipolar_pairs, mpchans = get_bp_tal_struct(sub, montage=mont, localization=loc)\n",
    "    elec_regions,atlas_type,pair_number,has_stein_das = get_elec_regions(localizations,pairs) \n",
    "\n",
    "    evs = reader.load(\"task_events\")\n",
    "    \n",
    "    if selected_period == 'countdown':\n",
    "\n",
    "        # -------------------------------------------------\n",
    "        # Check if COUNTDOWN_START or COUNTDOWN exist\n",
    "        # -------------------------------------------------\n",
    "        if \"COUNTDOWN_START\" not in evs[\"type\"].values:\n",
    "            if \"COUNTDOWN\" not in evs[\"type\"].values:\n",
    "                print(f\"{sub_sess} does NOT contain COUNTDOWN or COUNTDOWN_START.\")\n",
    "            else:\n",
    "                # Proceed with new countdown pivot/duration checks\n",
    "                countdown2 = evs.query(\"type in ['COUNTDOWN','ENCODING_START']\")\n",
    "                countdown2_pivot = countdown2.pivot_table(\n",
    "                    index=\"list\",\n",
    "                    columns=\"type\",\n",
    "                    values=\"mstime\",\n",
    "                    aggfunc=\"first\"\n",
    "                )\n",
    "                countdown2_pivot[\"countdown2_duration\"] = (\n",
    "                    countdown2_pivot[\"ENCODING_START\"] - countdown2_pivot[\"COUNTDOWN\"]\n",
    "                )\n",
    "\n",
    "                # Valid new countdown durations\n",
    "                good_countdown2_mask = (\n",
    "                    countdown2_pivot[\"countdown2_duration\"].notna() &\n",
    "                    (countdown2_pivot[\"countdown2_duration\"] >= 0)\n",
    "                )\n",
    "                good_lists = countdown2_pivot.index[good_countdown2_mask]\n",
    "\n",
    "                # Find minimum good new countdown duration\n",
    "                min_duration = countdown2_pivot.loc[\n",
    "                    good_lists,\n",
    "                    \"countdown2_duration\"\n",
    "                ].min()\n",
    "\n",
    "                # Check for \"bad\" new countdown threshold\n",
    "                if min_countdown2_duration < 9995:\n",
    "                    print(f\"{sub_sess}\")\n",
    "                    print(\"BAD NEW COUNTDOWN\")\n",
    "                    print(min_duration)\n",
    "                    \n",
    "                # Filter to final events for good lists\n",
    "                final_evs = evs[\n",
    "                    evs[\"list\"].isin(good_lists)\n",
    "                    & evs[\"type\"].isin([\"COUNTDOWN\"])\n",
    "                ]    \n",
    "        else:\n",
    "            # Proceed with countdown pivot/duration checks\n",
    "            countdown = evs.query(\"type in ['COUNTDOWN_START','COUNTDOWN_END']\")\n",
    "            countdown_pivot = countdown.pivot_table(\n",
    "                index=\"list\", \n",
    "                columns=\"type\", \n",
    "                values=\"mstime\", \n",
    "                aggfunc=\"first\"\n",
    "            )\n",
    "            countdown_pivot[\"countdown_duration\"] = (\n",
    "                countdown_pivot[\"COUNTDOWN_END\"] - countdown_pivot[\"COUNTDOWN_START\"]\n",
    "            )\n",
    "\n",
    "            # Valid countdown durations\n",
    "            good_countdown_mask = (\n",
    "                countdown_pivot[\"countdown_duration\"].notna() &\n",
    "                (countdown_pivot[\"countdown_duration\"] >= 0)\n",
    "            )\n",
    "            good_lists = countdown_pivot.index[good_countdown_mask]\n",
    "            \n",
    "            # a few lists have eegoffset<=0 which breaks things\n",
    "            bad_eegoffset_lists = evs.loc[evs[\"eegoffset\"] <= 0, \"list\"].unique()\n",
    "            good_lists = [lst for lst in good_lists if lst not in bad_eegoffset_lists] # filter out\n",
    "\n",
    "\n",
    "            # Find minimum good countdown duration\n",
    "            min_duration = countdown_pivot.loc[\n",
    "                good_lists, \n",
    "                \"countdown_duration\"\n",
    "            ].min()\n",
    "\n",
    "            # Check for \"bad\" countdown threshold\n",
    "            if min_duration < 9995:\n",
    "                print(f\"{sub_sess}\")\n",
    "                print(\"BAD COUNTDOWN\")\n",
    "                print(min_duration)\n",
    "            # Filter to final events for good lists\n",
    "            final_evs = evs[\n",
    "                evs[\"list\"].isin(good_lists)\n",
    "                & evs[\"type\"].isin([\"COUNTDOWN_START\"])\n",
    "            ]    \n",
    "\n",
    "    elif selected_period == 'distractor':\n",
    "        # -------------------------------------------------\n",
    "        # Check if DISTRACT_START exists\n",
    "        # -------------------------------------------------\n",
    "        if \"DISTRACT_START\" not in evs[\"type\"].values:\n",
    "            print(f\"{sub_sess} does NOT contain a distractor period.\")\n",
    "        else:\n",
    "            # Proceed with distractor pivot/duration checks\n",
    "            distractor = evs.query(\"type in ['DISTRACT_START','DISTRACT_END']\")\n",
    "            distractor_pivot = distractor.pivot_table(\n",
    "                index=\"list\", \n",
    "                columns=\"type\", \n",
    "                values=\"mstime\", \n",
    "                aggfunc=\"first\"\n",
    "            )\n",
    "            distractor_pivot[\"distract_duration\"] = (\n",
    "                distractor_pivot[\"DISTRACT_END\"] - distractor_pivot[\"DISTRACT_START\"]\n",
    "            )\n",
    "\n",
    "            # Valid distractor durations\n",
    "            good_distractor_mask = (\n",
    "                distractor_pivot[\"distract_duration\"].notna() &\n",
    "                (distractor_pivot[\"distract_duration\"] >= 0)\n",
    "            )\n",
    "            good_lists = distractor_pivot.index[good_distractor_mask]\n",
    "\n",
    "            # Find minimum good distractor duration\n",
    "            min_duration = distractor_pivot.loc[\n",
    "                good_lists, \n",
    "                \"distract_duration\"\n",
    "            ].min()\n",
    "\n",
    "            # Check for \"bad\" distractor threshold\n",
    "            if min_duration < 19995:\n",
    "                print(f\"{sub_sess}\")\n",
    "                print(\"BAD DISTRACTOR\")\n",
    "                print(min_duration)\n",
    "            # Filter to final events for good lists\n",
    "            final_evs = evs[\n",
    "                evs[\"list\"].isin(good_lists)\n",
    "                & evs[\"type\"].isin([\"DISTRACT_START\"])\n",
    "            ]                \n",
    "\n",
    "    # outputs to save: final_evs, good_lists, and min_duration\n",
    "    psth_end = min_duration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad5afa63-8172-4253-86dc-88afc0f21710",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load eeg\n",
    "evs_encoding_words = evs_encoding_words[evs_encoding_words.eegoffset>-1]\n",
    "\n",
    "# fixing bad trials\n",
    "if sub == 'R1045E' and exp == 'FR1': # this one session has issues in eeg trials past these points so remove events\n",
    "    if selected_period == 'whole_retrieval':\n",
    "        eeg_events = eeg_events.iloc[:20,:] # only the first 20 retrieval periods have good eeg\n",
    "    elif selected_period == 'encoding':\n",
    "        eeg_events = eeg_events.iloc[:263,:] # same idea\n",
    "        encoded_word_key = encoded_word_key[:263]\n",
    "    else:\n",
    "        sys.exit() # too difficult to deal with for clustering analysis   \n",
    "        # eeg_events = eeg_events.iloc[:65,:] # only the first 66 recalls have good eeg\n",
    "\n",
    "# note I added the align_adjust now for whole_retrieval where I adjust all retrieval starts to beep_end\n",
    "align_adjust = 0\n",
    "eeg = reader.load_eeg(events=eeg_events, rel_start=psth_start-eeg_buffer+align_adjust, \n",
    "                      rel_stop=psth_end+eeg_buffer+align_adjust, clean=True, scheme=pairs) "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "eeg311",
   "language": "python",
   "name": "eeg311"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
