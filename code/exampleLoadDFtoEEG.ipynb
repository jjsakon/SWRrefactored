{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c8565ce5-e0eb-48c5-b577-fd51581941e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "make sure you read through and understand what getSWRpathInfo is doing\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd; pd.set_option('display.max_columns', 30)\n",
    "import numpy as np\n",
    "from cmlreaders import CMLReader, get_data_index\n",
    "import ptsa\n",
    "import sys\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from pylab import *\n",
    "from copy import copy\n",
    "from scipy import stats\n",
    "plt.rcParams['pdf.fonttype'] = 42; plt.rcParams['ps.fonttype'] = 42 # fix fonts for Illustrator\n",
    "# sys.path.append('/home1/john/SWRrefactored/code/SWR_modules/')\n",
    "sys.path.insert(0, '/home1/john/SWRrefactored/code/SWR_modules/')\n",
    "from SWRmodule import *\n",
    "from general import * #superVstack,findInd,findAinB\n",
    "import csv\n",
    "import os\n",
    "import dill, pickle\n",
    "import mne\n",
    "from copy import copy    \n",
    "from scipy.signal import firwin,filtfilt,kaiserord\n",
    "from ptsa.data.filters import ButterworthFilter, ResampleFilter, MorletWaveletFilter\n",
    "import xarray as xarray\n",
    "from brain_labels import HPC_labels, ENT_labels, PHC_labels, temporal_lobe_labels,\\\n",
    "                        MFG_labels, IFG_labels, nonHPC_MTL_labels, ENTPHC_labels, AMY_labels, ACC_OF_MFC_labels\n",
    "import pingouin as pg\n",
    "\n",
    "################################################################\n",
    "df = get_data_index(\"r1\") # all RAM subjects\n",
    "\n",
    "### CHOOSE HERE\n",
    "exp = 'catFR1' # 'catFR1' #'FR1'\n",
    "selected_period = 'countdown' \n",
    "# working trial periods in this program: countdown # distractor\n",
    "available_regions = {\n",
    "#     \"ACC_OF_labels\": ACC_OF_MFC_labels,   \n",
    "    \"HPC_labels\": HPC_labels,\n",
    "#     \"ENTPHC_labels\": ENTPHC_labels,\n",
    "#     \"AMY_labels\": AMY_labels\n",
    "}\n",
    "################################################################\n",
    "\n",
    "remove_soz_ictal = 0\n",
    "recall_minimum = 2000 #5000 # 2000\n",
    "filter_type = 'hamming'\n",
    "extra = '' #'- ZERO_IRI'\n",
    "\n",
    "save_path = f'/scratch/john/SWRrefactored/patient_info/{exp}/'\n",
    "brain_region_idxs = np.arange(len(available_regions))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "8a91e217-67e8-49bb-880e-49bdfc4587bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.path.exists(\n",
    "    f'/scratch/john/SWRrefactored/patient_info/temp_dfSWR_{selected_period}_{exp}.p'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "2af4e368-7826-42ac-8a81-6b06154289a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_region = HPC_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "ff896db0-d906-4d6c-a7c6-ae14b76ed5ae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n:param [int, str] temp_df_select: \\n    if int, then temp_df_select is used to index a row of temp_df\\n    if str, then must be name of a patient. function iterates through \\n    rows of temp_df until row.subject equals temp_df_select\\n\\n:param str selected_period: encoding, surrounding_recall, or whole_retrieval\\n:param str selected_region: which brain region to generate data for \\n:param str save_path: folder to save data in\\n:param str exp: catFR or FR\\n:param bool testing_mode: if in testing mode, saves data to \"test.p\" \\nso as to not overwrite existing data\\n'"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# def ClusterRunSWRs(row, selected_region,save_path, selected_period, \n",
    "#                    exp, testing_mode=False):\n",
    "\n",
    "'''\n",
    ":param [int, str] temp_df_select: \n",
    "    if int, then temp_df_select is used to index a row of temp_df\n",
    "    if str, then must be name of a patient. function iterates through \n",
    "    rows of temp_df until row.subject equals temp_df_select\n",
    "\n",
    ":param str selected_period: encoding, surrounding_recall, or whole_retrieval\n",
    ":param str selected_region: which brain region to generate data for \n",
    ":param str save_path: folder to save data in\n",
    ":param str exp: catFR or FR\n",
    ":param bool testing_mode: if in testing mode, saves data to \"test.p\" \n",
    "so as to not overwrite existing data\n",
    "'''\n",
    "\n",
    "### PARAMS ###\n",
    "\n",
    "##\n",
    "## NOTE: for looking at individual lags make sure min_recalls is set to 0 or will eliminate trials from low recall lists\n",
    "##\n",
    "\n",
    "save_values = 0\n",
    "\n",
    "# there are three periods this code is set up to look at: periods aligned to recall, the entire retrieval period, and the encoding period\n",
    "  # switch to determine which recalls to look at! (see details below)\n",
    "# (as of 2021 always leave this as 0, since I select for 4/6/etc below)\n",
    "# 0: Original analysis taking only recalls without a recall in 2 s IRI before them\n",
    "# 1: Take these same recalls, but keep only those WITH a recall within 2 s after they occur \n",
    "# 2: test condition where we look at second recalls within IRI ONLY (there is an initial recall in 2 s before current recall)\n",
    "# 3: isolated recalls with no other recalls +/- RECALL_MINIMUM s\n",
    "# 4: only first recall of every retrieval period\n",
    "# 5: take only those recalls that come second in retrieval period within 2 s of first retrieval\n",
    "# 6: take only NOT first recall of every retrieval period\n",
    "# 7: take only NOT first recall AND ISOLATED trials (this should REALLY maximize SWR bump)\n",
    "# 10: same as 0 but with no IRI (mostly just to see number of recalls)\n",
    "remove_soz_ictal = 0 # 0 for nothing, 1 for SOZ, 2 for SOZ+ictal    \n",
    "min_ripple_rate = 0.025 # Hz. # 0.1\n",
    "max_ripple_rate = 1.5 # Hz.\n",
    "max_trial_by_trial_correlation = 0.05 # if ripples correlated more than this remove them\n",
    "max_electrode_by_electrode_correlation = 0.2\n",
    "\n",
    "### semantic/temporal clustering parameters ###\n",
    "min_recalls = 0\n",
    "PCA_ndim = 1 # number of PC dims to use for semantic clustering (Ethan usually found only 1 worked for theta/FC)\n",
    "\n",
    "#     # for parametric run through recall_minimums\n",
    "#         recall_mins = np.arange(800,5100,100) #[800,900,1100,1200,1300,1400]\n",
    "# #     recall_mins = [1600,1700,1800,1900,2100,2200,2300,2400,2500,2600,2700,2800,2900,3000]\n",
    "#     for recall_minimum in recall_mins:\n",
    "\n",
    "# recall params\n",
    "#     recall_minimum = 5000 # for isolated recalls what is minimum time for recall to be considered isolated?\n",
    "IRI = 2000 #5000 # inter-recall interval...remove recalls within this range (keep only first one and remove those after it)\n",
    "retrieval_whole_time = 10000\n",
    "# encoding params\n",
    "encoding_time = 2300 # actual preentation is 1.6 s + 0.75-1.0 s so keep +700 ms so can plot +500 ms\n",
    "pre_encoding_time = -700 # since minimum ISI is 0.75 s let's only plot the 500 ms before word on with a 200 ms buffer\n",
    "# these aren't likely to be changed:\n",
    "desired_sample_rate = 500. # in Hz. This seems like lowerst common denominator recording freq.\n",
    "eeg_buffer = 1000 # buffer to add to either end of IRI when processing eeg #**\n",
    "filter_type = 'hamming' # see local version below for details. 'butter' is removed from cluster version so don't change this    \n",
    "\n",
    "### END PARAMS ###    \n",
    "\n",
    "# get region label\n",
    "if selected_region == HPC_labels:\n",
    "    region_name = 'HPC'\n",
    "elif selected_region == ENT_labels:\n",
    "    region_name = 'ENT'\n",
    "elif selected_region == PHC_labels:\n",
    "    region_name = 'PHC'\n",
    "elif selected_region == temporal_lobe_labels:\n",
    "    region_name = 'TEMPORALLOBE'\n",
    "elif selected_region == MFG_labels:\n",
    "    region_name = 'MFG'\n",
    "elif selected_region == IFG_labels:\n",
    "    region_name = 'IFG'\n",
    "elif selected_region == nonHPC_MTL_labels:\n",
    "    region_name = 'nonHPC_MTL'\n",
    "elif selected_region == ENTPHC_labels:\n",
    "    region_name = 'ENTPHC'\n",
    "elif selected_region == AMY_labels:\n",
    "    region_name = 'AMY'\n",
    "elif selected_region == ACC_OF_MFC_labels:\n",
    "    region_name = 'ACC_OF'\n",
    "\n",
    "if selected_period == 'surrounding_recall':\n",
    "    if IRI == 0:\n",
    "        psth_start = -2000\n",
    "        psth_end = 2000\n",
    "    else:\n",
    "        psth_start = -IRI # only makes sense to look at period <= IRI\n",
    "        psth_end = IRI # how long to grab data after recall\n",
    "elif selected_period == 'whole_retrieval':\n",
    "    psth_start = -IRI # doesn't have to be IRI just 2000 ms is convenient\n",
    "    psth_end = IRI+retrieval_whole_time\n",
    "elif selected_period == 'encoding':\n",
    "    psth_start = pre_encoding_time\n",
    "    psth_end = encoding_time\n",
    "elif selected_period == 'countdown':\n",
    "    psth_start = 0\n",
    "elif selected_period == 'distractor':\n",
    "    psth_start = 0\n",
    "\n",
    "ripple_array = []; fr_array = []; \n",
    "trial_nums = []; \n",
    "elec_names = []; sub_sess_names = []; sub_names = []\n",
    "electrodes_per_session = []\n",
    "total_lists = 0; total_recalls = 0; kept_recalls = 0\n",
    "align_adjust = 0\n",
    "ent_elec_ct = []; sd_regions = []; not_sd_regions = []\n",
    "ripple_ied_accum_ct = []\n",
    "time_add_save = []\n",
    "encoded_word_key_array = []; category_array = []\n",
    "\n",
    "session_ripple_rate_by_elec = []; # for cluster version only since I compare across electrodes for each session\n",
    "\n",
    "list_recall_num_array = []; rectime_array = []; # new ones added 2020-11-24\n",
    "serialpos_array = [] # used to be encoding info but commandeered for surrounding_recalls ~~~\n",
    "recall_position_array = []\n",
    "session_events = pd.DataFrame()\n",
    "\n",
    "trial_by_trial_correlation = []; elec_by_elec_correlation = []\n",
    "elec_ripple_rate_array = []\n",
    "channel_coords = []; electrode_labels = []\n",
    "\n",
    "semantic_clustering_key = []\n",
    "temporal_clustering_key = []\n",
    "semantic_clustering_from_key = []\n",
    "serialpos_lags = []; serialpos_from_lags = []; CRP_lags = []\n",
    "list_trial_nums = []; list_num_key = []\n",
    "list_level_semantic = []; list_level_temporal = []\n",
    "\n",
    "program_ran = 0\n",
    "\n",
    "\n",
    "with open(f'/scratch/john/SWRrefactored/patient_info/temp_dfSWR_encoding_{exp}.p', 'rb') as f: ### change here to avoid overwrite\n",
    "    temp_df = dill.load(f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "9cfd414b-d9bd-409a-aabd-26280cf61da3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home1/john/anaconda3/envs/eeg311/lib/python3.11/site-packages/ptsa/data/readers/tal.py:41: FutureWarning: Lab-specific readers may be moved to the cmlreaders package (https://github.com/pennmem/cmlreaders)\n",
      "  warnings.warn(\"Lab-specific readers may be moved to the cmlreaders \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Not setting metadata\n",
      "26 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Adding metadata with 23 columns\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table class=\"table table-hover table-striped table-sm table-responsive small\">\n",
       "    <tr>\n",
       "        <th>Number of events</th>\n",
       "        <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <th>Events</th>\n",
       "        \n",
       "        <td>1: 26</td>\n",
       "        \n",
       "    </tr>\n",
       "    <tr>\n",
       "        <th>Time range</th>\n",
       "        <td>-1.000 – 11.426 s</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <th>Baseline</th>\n",
       "        <td>off</td>\n",
       "    </tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<EpochsArray |  26 events (all good), -1 – 11.426 s, baseline off, ~1.2 MB, data loaded, with metadata,\n",
       " '1': 26>"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--Call--\n",
      "> \u001b[0;32m/home1/john/anaconda3/envs/eeg311/lib/python3.11/site-packages/IPython/core/displayhook.py\u001b[0m(258)\u001b[0;36m__call__\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m    257 \u001b[0;31m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m--> 258 \u001b[0;31m    \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    259 \u001b[0;31m        \"\"\"Printing with history cache management.\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  u\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> \u001b[0;32m/tmp/3787566.1.jupyter.q/ipykernel_65601/1670632490.py\u001b[0m(248)\u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m    247 \u001b[0;31m\u001b[0;31m#         #sys.exit()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m--> 248 \u001b[0;31m    \u001b[0;32mimport\u001b[0m \u001b[0mipdb\u001b[0m\u001b[0;34m;\u001b[0m \u001b[0mipdb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_trace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    249 \u001b[0;31m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  q\n"
     ]
    }
   ],
   "source": [
    "max_sess = len(temp_df)\n",
    "\n",
    "for num in range(100,max_sess):\n",
    "    row = temp_df[num]\n",
    "\n",
    "    sub = row.subject\n",
    "    session = row.session\n",
    "    exp = row.experiment\n",
    "    mont = int(row.montage)\n",
    "    loc = int(row.localization)\n",
    "    sub_sess = f\"{sub}-{session}\"  # for convenience\n",
    "\n",
    "    reader = CMLReadDFRow(row)\n",
    "    \n",
    "    # get localizations (region info)\n",
    "    pairs = reader.load('pairs')\n",
    "    try:\n",
    "        localizations = reader.load('localization')\n",
    "    except:\n",
    "        localizations = []\n",
    "    tal_struct, bipolar_pairs, mpchans = get_bp_tal_struct(sub, montage=mont, localization=loc)\n",
    "    elec_regions,atlas_type,pair_number,has_stein_das = get_elec_regions(localizations,pairs) \n",
    "    elec_labels = pairs.label\n",
    "\n",
    "    evs = reader.load(\"task_events\")\n",
    "    \n",
    "    if selected_period == 'countdown':\n",
    "\n",
    "        # -------------------------------------------------\n",
    "        # Check if COUNTDOWN_START or COUNTDOWN exist\n",
    "        # -------------------------------------------------\n",
    "        if \"COUNTDOWN_START\" not in evs[\"type\"].values:\n",
    "            if \"COUNTDOWN\" not in evs[\"type\"].values:\n",
    "                print(f\"{sub_sess} does NOT contain COUNTDOWN or COUNTDOWN_START.\")\n",
    "            else:\n",
    "                # Proceed with new countdown pivot/duration checks\n",
    "                countdown2 = evs.query(\"type in ['COUNTDOWN','ENCODING_START']\")\n",
    "                countdown2_pivot = countdown2.pivot_table(\n",
    "                    index=\"list\",\n",
    "                    columns=\"type\",\n",
    "                    values=\"mstime\",\n",
    "                    aggfunc=\"first\"\n",
    "                )\n",
    "                countdown2_pivot[\"countdown2_duration\"] = (\n",
    "                    countdown2_pivot[\"ENCODING_START\"] - countdown2_pivot[\"COUNTDOWN\"]\n",
    "                )\n",
    "\n",
    "                # Valid new countdown durations\n",
    "                good_countdown2_mask = (\n",
    "                    countdown2_pivot[\"countdown2_duration\"].notna() &\n",
    "                    (countdown2_pivot[\"countdown2_duration\"] >= 0)\n",
    "                )\n",
    "                good_lists = countdown2_pivot.index[good_countdown2_mask]\n",
    "\n",
    "                # Find minimum good new countdown duration\n",
    "                min_duration = countdown2_pivot.loc[\n",
    "                    good_lists,\n",
    "                    \"countdown2_duration\"\n",
    "                ].min()\n",
    "\n",
    "                # Check for \"bad\" new countdown threshold\n",
    "                if min_countdown2_duration < 9995:\n",
    "                    print(f\"{sub_sess}\")\n",
    "                    print(\"BAD NEW COUNTDOWN\")\n",
    "                    print(min_duration)\n",
    "                    \n",
    "                # Filter to final events for good lists\n",
    "                final_evs = evs[\n",
    "                    evs[\"list\"].isin(good_lists)\n",
    "                    & evs[\"type\"].isin([\"COUNTDOWN\"])\n",
    "                ]    \n",
    "        else:\n",
    "            # Proceed with countdown pivot/duration checks\n",
    "            countdown = evs.query(\"type in ['COUNTDOWN_START','COUNTDOWN_END']\")\n",
    "            countdown_pivot = countdown.pivot_table(\n",
    "                index=\"list\", \n",
    "                columns=\"type\", \n",
    "                values=\"mstime\", \n",
    "                aggfunc=\"first\"\n",
    "            )\n",
    "            countdown_pivot[\"countdown_duration\"] = (\n",
    "                countdown_pivot[\"COUNTDOWN_END\"] - countdown_pivot[\"COUNTDOWN_START\"]\n",
    "            )\n",
    "\n",
    "            # Valid countdown durations\n",
    "            good_countdown_mask = (\n",
    "                countdown_pivot[\"countdown_duration\"].notna() &\n",
    "                (countdown_pivot[\"countdown_duration\"] >= 0)\n",
    "            )\n",
    "            good_lists = countdown_pivot.index[good_countdown_mask]\n",
    "            \n",
    "            # a few lists have eegoffset<=0 which breaks things\n",
    "            bad_eegoffset_lists = evs.loc[evs[\"eegoffset\"] <= 0, \"list\"].unique()\n",
    "            good_lists = [lst for lst in good_lists if lst not in bad_eegoffset_lists] # filter out\n",
    "\n",
    "\n",
    "            # Find minimum good countdown duration\n",
    "            min_duration = countdown_pivot.loc[\n",
    "                good_lists, \n",
    "                \"countdown_duration\"\n",
    "            ].min()\n",
    "\n",
    "            # Check for \"bad\" countdown threshold\n",
    "            if min_duration < 9995:\n",
    "                print(f\"{sub_sess}\")\n",
    "                print(\"BAD COUNTDOWN\")\n",
    "                print(min_duration)\n",
    "            # Filter to final events for good lists\n",
    "            final_evs = evs[\n",
    "                evs[\"list\"].isin(good_lists)\n",
    "                & evs[\"type\"].isin([\"COUNTDOWN_START\"])\n",
    "            ]    \n",
    "\n",
    "    elif selected_period == 'distractor':\n",
    "        # -------------------------------------------------\n",
    "        # Check if DISTRACT_START exists\n",
    "        # -------------------------------------------------\n",
    "        if \"DISTRACT_START\" not in evs[\"type\"].values:\n",
    "            print(f\"{sub_sess} does NOT contain a distractor period.\")\n",
    "        else:\n",
    "            # Proceed with distractor pivot/duration checks\n",
    "            distractor = evs.query(\"type in ['DISTRACT_START','DISTRACT_END']\")\n",
    "            distractor_pivot = distractor.pivot_table(\n",
    "                index=\"list\", \n",
    "                columns=\"type\", \n",
    "                values=\"mstime\", \n",
    "                aggfunc=\"first\"\n",
    "            )\n",
    "            distractor_pivot[\"distract_duration\"] = (\n",
    "                distractor_pivot[\"DISTRACT_END\"] - distractor_pivot[\"DISTRACT_START\"]\n",
    "            )\n",
    "\n",
    "            # Valid distractor durations\n",
    "            good_distractor_mask = (\n",
    "                distractor_pivot[\"distract_duration\"].notna() &\n",
    "                (distractor_pivot[\"distract_duration\"] >= 0)\n",
    "            )\n",
    "            good_lists = distractor_pivot.index[good_distractor_mask]\n",
    "\n",
    "            # Find minimum good distractor duration\n",
    "            min_duration = distractor_pivot.loc[\n",
    "                good_lists, \n",
    "                \"distract_duration\"\n",
    "            ].min()\n",
    "\n",
    "            # Check for \"bad\" distractor threshold\n",
    "            if min_duration < 19995:\n",
    "                print(f\"{sub_sess}\")\n",
    "                print(\"BAD DISTRACTOR\")\n",
    "                print(min_duration)\n",
    "            # Filter to final events for good lists\n",
    "            final_evs = evs[\n",
    "                evs[\"list\"].isin(good_lists)\n",
    "                & evs[\"type\"].isin([\"DISTRACT_START\"])\n",
    "            ]                \n",
    "\n",
    "    # outputs to save: final_evs, good_lists, and min_duration\n",
    "    psth_end = min_duration\n",
    "    \n",
    "            ### load eeg ###\n",
    "\n",
    "    # fixing bad trials\n",
    "    if sub == 'R1045E' and exp == 'FR1': # this one session has issues in eeg trials past these points so remove events\n",
    "        final_evs = final_evs.iloc[:20,:] # only the first 20 lists have good eeg\n",
    "        \n",
    "\n",
    "    # note I added the align_adjust now for whole_retrieval where I adjust all retrieval starts to beep_end\n",
    "    align_adjust = 0\n",
    "    eeg = reader.load_eeg(events=final_evs, rel_start=psth_start-eeg_buffer+align_adjust, \n",
    "                          rel_stop=psth_end+eeg_buffer+align_adjust, clean=True, scheme=pairs) \n",
    "\n",
    "\n",
    "    # events X electrodes X time\n",
    "    sr = eeg.samplerate\n",
    "\n",
    "    # if weird samplerate, add a few ms to make the load work\n",
    "    if (499<sr<500) | (998<sr<1000):\n",
    "        time_add = 1\n",
    "        if (499<sr<500):\n",
    "            sr = 500\n",
    "        elif (998<sr<1000):\n",
    "            sr = 1000\n",
    "        while eeg.shape[2] < (psth_end-psth_start+2*eeg_buffer)/(1000/sr):\n",
    "            eeg = reader.load_eeg(events=eeg_events, rel_start=int(psth_start-eeg_buffer+align_adjust), \n",
    "                                  rel_stop=int(psth_end+eeg_buffer+time_add+align_adjust), clean=True, scheme=pairs)\n",
    "            if time_add>50: #** \n",
    "                print(\"Time add is greater than 50\")\n",
    "                add_session_to_exclude_list(\"Time add is greater than 50\")\n",
    "                sys.exit()\n",
    "            time_add+=1\n",
    "        time_add_save.append(time_add)\n",
    "        eeg.samplerate = sr # need to overwrite those that were just fixed\n",
    "\n",
    "    eeg_mne = eeg.to_mne()\n",
    "    eeg = None # clear variable\n",
    "\n",
    "    # only analyze data in the region of interest\n",
    "    selected_elecs = []\n",
    "    for idx, elec_region in enumerate(elec_regions):\n",
    "        if elec_region in selected_region:\n",
    "            selected_elecs.append(idx)\n",
    "\n",
    "    # get bad channel mask\n",
    "    try:\n",
    "        elec_cats = reader.load('electrode_categories') # this is cool\n",
    "    except:\n",
    "        if remove_soz_ictal == True:\n",
    "            print(\"Remove soz ictal is true\")\n",
    "            add_session_to_exclude_list(\"Remove soz ictal is true\")\n",
    "            sys.exit() # don't know soz/ictal sites so skip this session\n",
    "        else: \n",
    "            elec_cats = [] # not removing these sites anyway so keep on keeping on\n",
    "#             e = 'No electrode categories for '+sub+', session '+str(session)\n",
    "#             LogDFExceptionLine(row, e, 'SWR_get_eeg_log.txt')\n",
    "\n",
    "    bad_bp_mask = getBadChannels(tal_struct,elec_cats,remove_soz_ictal)\n",
    "    bad_electrode_idxs = np.argwhere(bad_bp_mask!=0)\n",
    "\n",
    "    \n",
    "    # remove bad electrodes \n",
    "    selected_elecs = np.setdiff1d(selected_elecs, bad_electrode_idxs)\n",
    "    eeg_mne.pick(selected_elecs)\n",
    "    # update names, regions, and labels\n",
    "    selected_elecs_regions = elec_regions[selected_elecs] \n",
    "    selected_elecs_labels = elec_labels[selected_elecs]    \n",
    "    channel_coords = []\n",
    "    for channel in selected_elecs:\n",
    "        if 'avg.x' in pairs:\n",
    "            temp_coord = np.array([pairs.iloc[channel]['avg.x'], pairs.iloc[channel]['avg.y'], pairs.iloc[channel]['avg.z']])\n",
    "        elif 'ind.x' in pairs:\n",
    "            temp_coord = np.array([pairs.iloc[channel]['ind.x'], pairs.iloc[channel]['ind.y'], pairs.iloc[channel]['ind.z']])\n",
    "        else:\n",
    "            temp_coord = np.full(3, np.nan)\n",
    "        channel_coords.append(temp_coord)\n",
    "        \n",
    "\n",
    "#     # downsample sr to 500 \n",
    "#     if sr > 500:\n",
    "#         sr = 500\n",
    "#         eeg_mne = eeg_mne.resample(sfreq=sr)\n",
    "\n",
    "#     elif sr == 500:\n",
    "#         pass\n",
    "#     else:\n",
    "#         print(\"Sampling rate is too low: \", sr)\n",
    "#         add_session_to_exclude_list(\"Sampling rate is too low\")\n",
    "#         #sys.exit()\n",
    "    import ipdb; ipdb.set_trace()\n",
    "    \n",
    "    if save_values == 1:\n",
    "\n",
    "    # get strings for path name for save and loading cluster data\n",
    "        try:\n",
    "            path_name = save_path+selected_period+'/'\n",
    "\n",
    "            if os.path.isdir(path_name) == False:\n",
    "                os.makedirs(path_name)\n",
    "\n",
    "            if testing_mode:\n",
    "                fn = os.path.join(path_name, 'test.p')\n",
    "            else:\n",
    "                fn = os.path.join(path_name,\n",
    "                'RAW_'+exp+'_'+sub+'_'+str(session)+'_'+region_name+'_'+selected_period+'.p') \n",
    "\n",
    "            print(\"SAVE FILE NAME: \", fn) \n",
    "            \n",
    "            with open(fn,'wb') as f:\n",
    "                pickle.dump({'elec_regions':selected_elecs_regions,\n",
    "                            'elec_labels':selected_elecs_labels,\n",
    "                            'raw_eeg':eeg_mne._data,\n",
    "                            'time_add_save':time_add_save,\n",
    "                            'events_df':final_evs,\n",
    "                            'electrode_coords':channel_coords,\n",
    "                            'eeg_buffer':eeg_buffer,\n",
    "                            'kept_lists':good_lists,\n",
    "                            'min_duration':min_duration,\n",
    "                            'sampling_rate':sr}, f)\n",
    "            print(\"Saved data\")\n",
    "\n",
    "        except:\n",
    "#             LogDFExceptionLine(row, e, '/home1/john/logs/COUNTDOWNandDISTRACTOReeg.txt') \n",
    "            print(\"Could not save file\")\n",
    "\n",
    "#     else:\n",
    "#         print(\"Save values: \", save_values)      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "3ec5bf45-bb9a-4f83-98e8-481f100b38f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(26, 1, 6214)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.shape(eeg_mne)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "78562a49-2ba7-4810-b99c-528cfdc01b08",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "elec_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b61b568-377c-45f4-b2ad-850d62700c60",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "eeg311",
   "language": "python",
   "name": "eeg311"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
