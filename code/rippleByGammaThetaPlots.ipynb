{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fc17f345-6597-4a33-8ed8-1b3b07d4e1c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "In /home1/john/anaconda3/envs/workshopJ/lib/python3.7/site-packages/matplotlib/mpl-data/stylelib/_classic_test.mplstyle: \n",
      "The text.latex.preview rcparam was deprecated in Matplotlib 3.3 and will be removed two minor releases later.\n",
      "In /home1/john/anaconda3/envs/workshopJ/lib/python3.7/site-packages/matplotlib/mpl-data/stylelib/_classic_test.mplstyle: \n",
      "The mathtext.fallback_to_cm rcparam was deprecated in Matplotlib 3.3 and will be removed two minor releases later.\n",
      "In /home1/john/anaconda3/envs/workshopJ/lib/python3.7/site-packages/matplotlib/mpl-data/stylelib/_classic_test.mplstyle: Support for setting the 'mathtext.fallback_to_cm' rcParam is deprecated since 3.3 and will be removed two minor releases later; use 'mathtext.fallback : 'cm' instead.\n",
      "In /home1/john/anaconda3/envs/workshopJ/lib/python3.7/site-packages/matplotlib/mpl-data/stylelib/_classic_test.mplstyle: \n",
      "The validate_bool_maybe_none function was deprecated in Matplotlib 3.3 and will be removed two minor releases later.\n",
      "In /home1/john/anaconda3/envs/workshopJ/lib/python3.7/site-packages/matplotlib/mpl-data/stylelib/_classic_test.mplstyle: \n",
      "The savefig.jpeg_quality rcparam was deprecated in Matplotlib 3.3 and will be removed two minor releases later.\n",
      "In /home1/john/anaconda3/envs/workshopJ/lib/python3.7/site-packages/matplotlib/mpl-data/stylelib/_classic_test.mplstyle: \n",
      "The keymap.all_axes rcparam was deprecated in Matplotlib 3.3 and will be removed two minor releases later.\n",
      "In /home1/john/anaconda3/envs/workshopJ/lib/python3.7/site-packages/matplotlib/mpl-data/stylelib/_classic_test.mplstyle: \n",
      "The animation.avconv_path rcparam was deprecated in Matplotlib 3.3 and will be removed two minor releases later.\n",
      "In /home1/john/anaconda3/envs/workshopJ/lib/python3.7/site-packages/matplotlib/mpl-data/stylelib/_classic_test.mplstyle: \n",
      "The animation.avconv_args rcparam was deprecated in Matplotlib 3.3 and will be removed two minor releases later.\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload\n",
    "\n",
    "import pandas as pd; pd.set_option('display.max_columns', 30)\n",
    "import numpy as np\n",
    "from cmlreaders import CMLReader, get_data_index\n",
    "import ptsa\n",
    "import sys\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sb\n",
    "from pylab import *\n",
    "from copy import copy\n",
    "from scipy import stats\n",
    "plt.rcParams['pdf.fonttype'] = 42; plt.rcParams['ps.fonttype'] = 42 # fix fonts for Illustrator\n",
    "sys.path.append('/home1/john/SWRrefactored/code/SWR_modules/')\n",
    "from SWRmodule import *\n",
    "from general import * #superVstack,findInd,findAinB\n",
    "from power_functions import z_score, process_power, load_z_scored_power\n",
    "\n",
    "base = '/home1/john/SWRrefactored'\n",
    "sys.path.append(f'{base}/code/')\n",
    "\n",
    "from load_data_numpy import load_data_np\n",
    "from SWRmodule import triangleSmooth\n",
    "# from comodulogram import remove_session_string, get_filtered_signal\n",
    "# from fooof import FOOOF\n",
    "\n",
    "import statsmodels.formula.api as smf\n",
    "from scipy.signal import decimate, resample, hilbert, welch, spectrogram\n",
    "from mne.time_frequency import tfr_array_morlet\n",
    "\n",
    "# # Import the time & event model objects and Bands object to manage oscillation band definitions\n",
    "# from specparam import SpectralTimeModel, SpectralTimeEventModel, Bands\n",
    "# # Import helper utilities for simulating and plotting spectrograms\n",
    "# from specparam.sim import sim_spectrogram\n",
    "# from specparam.plts.spectra import plot_spectrogram\n",
    "\n",
    "# np.logspace(np.log10(80),np.log10(178),10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5846d65a-6e2d-4517-a199-5519e465efa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for now the plotting code only works with one region at a time\n",
    "region_name = ['HPC'] # ['ENT'] # ['AMY'] ['HPC']\n",
    "subregion = ['ca1'] #['ca1'] # can use [''] to select ALL subregions\n",
    "task = 'catFR1' # 'catFR1'\n",
    "savePath = f'{base}/figures/'\n",
    "\n",
    "# 1 for encoding, 0 for recall\n",
    "encoding_mode_arr = [1] #[0,1] \n",
    "freq_range_str_arr = [[33.5,75]] #[[33.5,75],[80,120]] #,[2,4],[7,9]] # [80,178]\n",
    "# these were selecetd to avoid 60 and 120 Hz using np.logspace(np.log10(30),np.log10(75),10)\n",
    "\n",
    "fs = 500 # sampling rate for raw data and ripples from createEventsForDF.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "105c8ab8-3da0-405c-921b-f9ae99143a46",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data\n",
      "LOADING DATA FROM: HPC FOR EXPERIMENT catFR1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home1/john/anaconda3/envs/workshopJ/lib/python3.7/site-packages/numpy/core/fromnumeric.py:43: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  result = getattr(asarray(obj), method)(*args, **kwds)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "order: C\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home1/john/SWRrefactored/code/SWR_modules/load_data.py:436: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  dd_trials[key] = np.asarray(val)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating figures for run_mode:  1\n"
     ]
    }
   ],
   "source": [
    "for encoding_mode in encoding_mode_arr:\n",
    "\n",
    "    dd_trials = load_data_np(encoding_mode,task,\n",
    "        region_name=region_name, train_only=False, subregion=subregion)\n",
    "\n",
    "    region_str = region_name[0]\n",
    "    subregion_str = subregion[0]\n",
    "    \n",
    "    clust = dd_trials['clust_int']\n",
    "    \n",
    "    start_cutoff = 0 # in samples\n",
    "    if encoding_mode == 1: # raw is from -1.7 to 3.3 s from word_on\n",
    "        saveName = 'encoding_'\n",
    "        recall_str = ''\n",
    "        correct = dd_trials['correct']\n",
    "        incorrect_idxs = np.argwhere(correct==0).squeeze()\n",
    "        end_cutoff = 2500 # just take the whole range of data to better estimate Morlet     \n",
    " \n",
    "    elif encoding_mode == 0: # raw is from -3 to 3 s from recall\n",
    "        saveName = 'recall_'\n",
    "        recall_str = '_recall'\n",
    "        end_cutoff = 3000 # just take the whole range of data to better estimate Morlet       \n",
    "\n",
    "    sr_factor = 1000/fs\n",
    "    \n",
    "    print(\"Generating figures for run_mode: \", encoding_mode)\n",
    "    # starts with high and moves to low\n",
    "    power_z = load_z_scored_power(dd_trials, freq_range_str_arr, encoding_mode,fs,start_cutoff, end_cutoff)\n",
    "        \n",
    "    # note that output is 50 Hz (20 ms bins) since started 500 hz and decimated 10x\n",
    "    if len(subregion[0]) > 0:\n",
    "        subregion_str = f'_{subregion[0]}'\n",
    "    else:\n",
    "        subregion_str = ''           \n",
    "\n",
    "a=1;            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "306ee27f-6e67-4b7d-8287-69622a8cca9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# info\n",
    "dd_trials.keys()\n",
    "np.shape(dd_trials['ripple'])\n",
    "np.shape(dd_trials['raw'])\n",
    "\n",
    "np.shape(power_z)\n",
    "freq_range_str_arr\n",
    "\n",
    "unique_subs = np.unique(dd_trials['subj'])\n",
    "unique_subs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c8960e2-8765-4f83-9a75-ad842b2c1c6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "gamma_sd_thresh = 1.5\n",
    "remove_first_recalls = 0 # if looking at recall might want to remove first recall of each list\n",
    "\n",
    "# select a patient?\n",
    "patient_idx = -1 # -1 means all\n",
    "\n",
    "if patient_idx >-1: \n",
    "    sub_idxs = dd_trials['subj']==unique_subs[patient_idx]\n",
    "else:\n",
    "    sub_idxs = np.ones(len(dd_trials['subj']),dtype=bool)\n",
    "print(f'Number of trials: {sum(sub_idxs)} from the following subs:')\n",
    "np.unique(dd_trials['subj'][sub_idxs])\n",
    "\n",
    "# if recalls remove the intrusions\n",
    "if encoding_mode == 0:\n",
    "    if remove_first_recalls:\n",
    "        final_sub_idxs = (sub_idxs) & (clust!=0) & (dd_trials['recall_pos']!=1)\n",
    "    else:\n",
    "        final_sub_idxs = (sub_idxs) & (clust!=0)\n",
    "else:\n",
    "    final_sub_idxs = sub_idxs\n",
    "      \n",
    "# update each variable with indices\n",
    "sub_ripples = dd_trials['ripple'][final_sub_idxs] # ripples are detected from -0.7 to 2.3 s @ 500 Hz\n",
    "if power_z.ndim == 2:\n",
    "    power_z = power_z[np.newaxis, :, :]\n",
    "sub_Zs = power_z[:,final_sub_idxs,:]\n",
    "sub_clust_ID = clust[final_sub_idxs]\n",
    "np.shape(sub_Zs)\n",
    "\n",
    "z_factor = sr_factor*10 # z_score was decimated 10x\n",
    "if encoding_mode == 1:\n",
    "    ripple_start_offset = -700 # # note only +700 since ripple_trials go from -0.7 to 2.3 s (no buffers)\n",
    "    ripple_analysis_start = 300 # time in ms\n",
    "    ripple_analysis_end = 1300 # time in ms\n",
    "    \n",
    "    # average z-score over time for same range as ripples\n",
    "    gamma_time_range = slice(int((1700+ripple_analysis_start)/z_factor),int((1700+ripple_analysis_end)/z_factor)) # +1700 since goes from -1.7 to 3.3 s   \n",
    "    \n",
    "elif encoding_mode == 0:\n",
    "    ripple_start_offset = -2000 # ripple matrix 2000 ms on either side of recall\n",
    "    ripple_analysis_start = -1900 # time in ms\n",
    "    ripple_analysis_end = -100 # time in ms    \n",
    "\n",
    "    # average z-score over time for same range as ripples\n",
    "    gamma_time_range = slice(int((2000+ripple_analysis_start)/z_factor),int((2000+ripple_analysis_end)/z_factor)) # +2000 since goes from -3 to 3 s\n",
    "\n",
    "# check power > thresh in gamma time range\n",
    "z_low_gamma_trials = np.mean(sub_Zs[0,:,gamma_time_range],1)>gamma_sd_thresh\n",
    "if np.shape(sub_Zs)[0]>1:\n",
    "    z_high_gamma_trials = np.mean(sub_Zs[1,:,gamma_time_range],1)>gamma_sd_thresh     \n",
    "    \n",
    "ripple_trials = np.sum(sub_ripples[:,int((-ripple_start_offset+ripple_analysis_start)/sr_factor):\n",
    "                                   int((-ripple_start_offset+ripple_analysis_end)/sr_factor)],1)>0\n",
    "print(f'{sum(ripple_trials)} trials have ripples which is {np.round(100*sum(ripple_trials)/sum(final_sub_idxs),2)}% of total')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c54752e1-4be1-4a56-b8b2-b6e54439b11a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"{len(np.unique(dd_trials['elec_labels'][sub_idxs]))} elecs\")\n",
    "print(f\"from {len(np.unique(dd_trials['sess'][sub_idxs]))} sessions\")\n",
    "print(f\"from {len(np.unique(dd_trials['subj'][sub_idxs]))} patients\")\n",
    "\n",
    "if region_name == ['ENT']:\n",
    "    ENT_sess = np.unique(dd_trials['sess'][sub_idxs])\n",
    "    ENT_sub = np.unique(dd_trials['subj'][sub_idxs])\n",
    "elif region_name == ['HPC']:\n",
    "    HPC_sess = np.unique(dd_trials['sess'][sub_idxs])\n",
    "    HPC_sub = np.unique(dd_trials['subj'][sub_idxs])\n",
    "elif region_name == ['AMY']:\n",
    "    AMY_sess = np.unique(dd_trials['sess'][sub_idxs])\n",
    "    AMY_sub = np.unique(dd_trials['subj'][sub_idxs])\n",
    "    \n",
    "save_sub_sess_info = 0\n",
    "\n",
    "if save_sub_sess_info == 1:\n",
    "    import pickle\n",
    "    with open('../misc/region_data.pkl', 'wb') as f:\n",
    "        pickle.dump({\n",
    "            'ENT_sess': ENT_sess,\n",
    "            'ENT_sub': ENT_sub,\n",
    "            'HPC_sess': HPC_sess,\n",
    "            'HPC_sub': HPC_sub,\n",
    "            'AMY_sess': AMY_sess,\n",
    "            'AMY_sub': AMY_sub\n",
    "        }, f)   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d257ae37-ab00-486a-a01d-ecf5dbf9a760",
   "metadata": {},
   "source": [
    "### get start_array!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91bd71fd-020f-4985-8a10-0265b3150f18",
   "metadata": {},
   "outputs": [],
   "source": [
    "start_array,_ = getStartEndArrays(sub_ripples)\n",
    "\n",
    "# first bin has artificially high number due to how start_srray works\n",
    "start_array = start_array[:,1:] \n",
    "print(f'start array shape: {np.shape(start_array)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b8b3f33-dc02-4cd3-9c82-cd220456ddca",
   "metadata": {},
   "source": [
    "# ripples after removing gamma trials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b087a7c1-51af-4299-a6bb-aa7ef309bed8",
   "metadata": {},
   "outputs": [],
   "source": [
    "remove_low_freq = 1 # 1 for low gamma/theta; 2 for high gamma/theta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5e8de0a-f33e-40dd-a9fb-7c77eb485820",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.gridspec as gridspec\n",
    "\n",
    "# Function parameters\n",
    "bin_size = 100  # in ms\n",
    "smoothing_triangle = 5  # triangular smoothing window width\n",
    "\n",
    "bar_ylimits = (0, 0.4)\n",
    "\n",
    "if remove_low_freq == 1:\n",
    "    trial_select = ~z_low_gamma_trials\n",
    "elif remove_low_freq == 2:\n",
    "    trial_select = ~z_high_gamma_trials\n",
    "else:\n",
    "    print('Invalid remove_low_freq selection')\n",
    "    error\n",
    "\n",
    "ripple_swarm_start = int((-ripple_start_offset+ripple_analysis_start)/sr_factor)\n",
    "ripple_swarm_end = int((-ripple_start_offset+ripple_analysis_end)/sr_factor)\n",
    "ripple_swarm_duration = (ripple_analysis_end-ripple_analysis_start)/1000  # convert to seconds\n",
    "\n",
    "# Apply the clust variable to split data into clustered, unclustered, and not recalled\n",
    "clust_clustered = sub_clust_ID > 1 # 1 means adjacent non-semantic\n",
    "clust_unclustered = sub_clust_ID < 0\n",
    "clust_not_recalled = sub_clust_ID == 0\n",
    "\n",
    "# Calculate ripple means and standard errors for each condition\n",
    "mean_ripple_clustered = np.sum(start_array[trial_select & clust_clustered, ripple_swarm_start:ripple_swarm_end], axis=1) / ripple_swarm_duration\n",
    "mean_ripple_unclustered = np.sum(start_array[trial_select & clust_unclustered, ripple_swarm_start:ripple_swarm_end], axis=1) / ripple_swarm_duration\n",
    "mean_ripple_not_recalled = np.sum(start_array[trial_select & clust_not_recalled, ripple_swarm_start:ripple_swarm_end], axis=1) / ripple_swarm_duration\n",
    "\n",
    "if encoding_mode == 1:\n",
    "    means = [np.mean(mean_ripple_clustered), np.mean(mean_ripple_unclustered), np.mean(mean_ripple_not_recalled)]\n",
    "    ses = [np.std(mean_ripple_clustered) / np.sqrt(len(mean_ripple_clustered)),\n",
    "           np.std(mean_ripple_unclustered) / np.sqrt(len(mean_ripple_unclustered)),\n",
    "           np.std(mean_ripple_not_recalled) / np.sqrt(len(mean_ripple_not_recalled))]\n",
    "    fig = plt.figure(figsize=(4, 5))\n",
    "elif encoding_mode == 0:\n",
    "    means = [np.mean(mean_ripple_clustered), np.mean(mean_ripple_unclustered)]\n",
    "    ses = [np.std(mean_ripple_clustered) / np.sqrt(len(mean_ripple_clustered)),\n",
    "           np.std(mean_ripple_unclustered) / np.sqrt(len(mean_ripple_unclustered))]    \n",
    "    fig = plt.figure(figsize=(3, 5))\n",
    "\n",
    "# Define the palette for colors\n",
    "palette = {\n",
    "    'Clustered': 'blue',\n",
    "    'Unclustered': 'orange',\n",
    "    'Not Recalled': 'green'\n",
    "}\n",
    "\n",
    "# Set up the figure with GridSpec\n",
    "gs = gridspec.GridSpec(2, 3, height_ratios=[2, 2], width_ratios=[3, 3, 3])\n",
    "\n",
    "# Create the bar plot with error bars (span all columns)\n",
    "ax_bar = fig.add_subplot(gs[0, :])\n",
    "if encoding_mode == 1:\n",
    "    xlabels = ['Clustered', 'Unclustered', 'Not Recalled']\n",
    "    xcolors = [palette['Clustered'], palette['Unclustered'], palette['Not Recalled']]\n",
    "elif encoding_mode == 0:\n",
    "    xlabels = ['Clustered', 'Unclustered']\n",
    "    xcolors = [palette['Clustered'], palette['Unclustered']]\n",
    "bars = ax_bar.bar(x=xlabels, \n",
    "                  height=means, \n",
    "                  color=xcolors, \n",
    "                  yerr=ses, \n",
    "                  width=0.5,  # Adjust width to make bars tighter\n",
    "                  capsize=5, \n",
    "                  error_kw=dict(ecolor='black', elinewidth=2))\n",
    "\n",
    "ax_bar.set_ylabel('Ripple rate by trial (Hz)')\n",
    "ax_bar.set_xlabel('')\n",
    "ax_bar.set_ylim(bar_ylimits)\n",
    "ax_bar.set_xticklabels(['Clustered', 'Unclustered', 'Not Recalled'], rotation=20, ha=\"center\")\n",
    "ax_bar.spines['right'].set_visible(False)\n",
    "ax_bar.spines['top'].set_visible(False)\n",
    "ax_bar.set_title('no low gamma trials')\n",
    "\n",
    "# Add the number of trials above each bar\n",
    "n_trials = [np.sum(trial_select & clust_clustered), \n",
    "            np.sum(trial_select & clust_unclustered), \n",
    "            np.sum(trial_select & clust_not_recalled)]\n",
    "for bar, n in zip(bars, n_trials):\n",
    "    ax_bar.text(bar.get_x() + bar.get_width() / 2, bar.get_height() + 0.01, f'n={n}', ha='center', va='bottom')\n",
    "\n",
    "# Calculate PSTH for each group\n",
    "ripple_PSTH_clustered, bin_centers = fullPSTH(start_array[trial_select & clust_clustered], bin_size, smoothing_triangle, fs, ripple_start_offset)\n",
    "ripple_PSTH_unclustered, _ = fullPSTH(start_array[trial_select & clust_unclustered], bin_size, smoothing_triangle, fs, ripple_start_offset)\n",
    "ripple_PSTH_not_recalled, _ = fullPSTH(start_array[trial_select & clust_not_recalled], bin_size, smoothing_triangle, fs, ripple_start_offset)\n",
    "\n",
    "# Plot the PSTH for each group\n",
    "ax_psth = fig.add_subplot(gs[1, :])\n",
    "ax_psth.plot(bin_centers / 1000, ripple_PSTH_clustered, label='Clustered', color=palette['Clustered'])\n",
    "ax_psth.plot(bin_centers / 1000, ripple_PSTH_unclustered, label='Unclustered', color=palette['Unclustered'])\n",
    "if encoding_mode == 1:\n",
    "    ax_psth.plot(bin_centers / 1000, ripple_PSTH_not_recalled, label='Not Recalled', color=palette['Not Recalled'])\n",
    "    ax_psth.axvline(x=0.0, color='black', linestyle='--')\n",
    "    ax_psth.axvline(x=1.6, color='black', linestyle='--')\n",
    "    ax_psth.set_xlim(-0.25, 2.05)\n",
    "elif encoding_mode == 0:\n",
    "    ax_psth.set_xlim(-2.0, 2.0)\n",
    "ax_psth.set_xlabel('Time (s)')\n",
    "ax_psth.set_ylim(0,bar_ylimits[1])\n",
    "ax_psth.set_ylabel('Ripple rate (Hz)')\n",
    "ax_psth.spines['right'].set_visible(False)\n",
    "ax_psth.spines['top'].set_visible(False)\n",
    "\n",
    "# Add legend to the bottom plot\n",
    "ax_psth.legend(loc='upper center', frameon=False)\n",
    "\n",
    "# Adjust layout\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "a=1;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0d5a8dd-f8a3-40c0-b6a6-a20c2ca89bd7",
   "metadata": {},
   "source": [
    "# ripples only for + gamma trials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc797628-58bb-4e9b-8f50-39c2c5ed2d2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function parameters\n",
    "bin_size = 100  # in ms\n",
    "smoothing_triangle = 5  # triangular smoothing window width\n",
    "\n",
    "bar_ylimits = (0, 0.52)\n",
    "\n",
    "if remove_low_freq == 1:\n",
    "    trial_select = z_low_gamma_trials\n",
    "elif remove_low_freq == 2:\n",
    "    trial_select = z_high_gamma_trials\n",
    "else:\n",
    "    print('Invalid remove_low_freq selection')\n",
    "    error\n",
    "\n",
    "ripple_swarm_start = int((-ripple_start_offset+ripple_analysis_start)/sr_factor)\n",
    "ripple_swarm_end = int((-ripple_start_offset+ripple_analysis_end)/sr_factor)\n",
    "ripple_swarm_duration = (ripple_analysis_end-ripple_analysis_start)/1000  # convert to seconds\n",
    "\n",
    "# Apply the clust variable to split data into clustered, unclustered, and not recalled\n",
    "clust_clustered = sub_clust_ID > 1\n",
    "clust_unclustered = sub_clust_ID < 0\n",
    "clust_not_recalled = sub_clust_ID == 0\n",
    "\n",
    "# Calculate ripple means and standard errors for each condition\n",
    "mean_ripple_clustered = np.sum(start_array[trial_select & clust_clustered, ripple_swarm_start:ripple_swarm_end], axis=1) / ripple_swarm_duration\n",
    "mean_ripple_unclustered = np.sum(start_array[trial_select & clust_unclustered, ripple_swarm_start:ripple_swarm_end], axis=1) / ripple_swarm_duration\n",
    "mean_ripple_not_recalled = np.sum(start_array[trial_select & clust_not_recalled, ripple_swarm_start:ripple_swarm_end], axis=1) / ripple_swarm_duration\n",
    "\n",
    "if encoding_mode == 1:\n",
    "    means = [np.mean(mean_ripple_clustered), np.mean(mean_ripple_unclustered), np.mean(mean_ripple_not_recalled)]\n",
    "    ses = [np.std(mean_ripple_clustered) / np.sqrt(len(mean_ripple_clustered)),\n",
    "           np.std(mean_ripple_unclustered) / np.sqrt(len(mean_ripple_unclustered)),\n",
    "           np.std(mean_ripple_not_recalled) / np.sqrt(len(mean_ripple_not_recalled))]\n",
    "    fig = plt.figure(figsize=(4, 5))\n",
    "elif encoding_mode == 0:\n",
    "    means = [np.mean(mean_ripple_clustered), np.mean(mean_ripple_unclustered)]\n",
    "    ses = [np.std(mean_ripple_clustered) / np.sqrt(len(mean_ripple_clustered)),\n",
    "           np.std(mean_ripple_unclustered) / np.sqrt(len(mean_ripple_unclustered))]    \n",
    "    fig = plt.figure(figsize=(3, 5))\n",
    "\n",
    "# Define the palette for colors\n",
    "palette = {\n",
    "    'Clustered': 'blue',\n",
    "    'Unclustered': 'orange',\n",
    "    'Not Recalled': 'green'\n",
    "}\n",
    "\n",
    "# Set up the figure with GridSpec\n",
    "gs = gridspec.GridSpec(2, 3, height_ratios=[2, 2], width_ratios=[3, 3, 3])\n",
    "\n",
    "# Create the bar plot with error bars (span all columns)\n",
    "ax_bar = fig.add_subplot(gs[0, :])\n",
    "if encoding_mode == 1:\n",
    "    xlabels = ['Clustered', 'Unclustered', 'Not Recalled']\n",
    "    xcolors = [palette['Clustered'], palette['Unclustered'], palette['Not Recalled']]\n",
    "elif encoding_mode == 0:\n",
    "    xlabels = ['Clustered', 'Unclustered']\n",
    "    xcolors = [palette['Clustered'], palette['Unclustered']]\n",
    "bars = ax_bar.bar(x=xlabels, \n",
    "                  height=means, \n",
    "                  color=xcolors, \n",
    "                  yerr=ses, \n",
    "                  width=0.5,  # Adjust width to make bars tighter\n",
    "                  capsize=5, \n",
    "                  error_kw=dict(ecolor='black', elinewidth=2))\n",
    "\n",
    "ax_bar.set_ylabel('Ripple rate by trial (Hz)')\n",
    "ax_bar.set_xlabel('')\n",
    "ax_bar.set_ylim(bar_ylimits)\n",
    "ax_bar.set_xticklabels(['Clustered', 'Unclustered', 'Not Recalled'], rotation=20, ha=\"center\")\n",
    "ax_bar.spines['right'].set_visible(False)\n",
    "ax_bar.spines['top'].set_visible(False)\n",
    "ax_bar.set_title('only low gamma trials')\n",
    "\n",
    "# Add the number of trials above each bar\n",
    "n_trials = [np.sum(trial_select & clust_clustered), \n",
    "            np.sum(trial_select & clust_unclustered), \n",
    "            np.sum(trial_select & clust_not_recalled)]\n",
    "for bar, n in zip(bars, n_trials):\n",
    "    ax_bar.text(bar.get_x() + bar.get_width() / 2, bar.get_height() + 0.03, f'n={n}', ha='center', va='bottom')\n",
    "\n",
    "# Calculate PSTH for each group\n",
    "ripple_PSTH_clustered, bin_centers = fullPSTH(start_array[trial_select & clust_clustered], bin_size, smoothing_triangle, fs, ripple_start_offset)\n",
    "ripple_PSTH_unclustered, _ = fullPSTH(start_array[trial_select & clust_unclustered], bin_size, smoothing_triangle, fs, ripple_start_offset)\n",
    "ripple_PSTH_not_recalled, _ = fullPSTH(start_array[trial_select & clust_not_recalled], bin_size, smoothing_triangle, fs, ripple_start_offset)\n",
    "\n",
    "# Plot the PSTH for each group\n",
    "ax_psth = fig.add_subplot(gs[1, :])\n",
    "ax_psth.plot(bin_centers / 1000, ripple_PSTH_clustered, label='Clustered', color=palette['Clustered'])\n",
    "ax_psth.plot(bin_centers / 1000, ripple_PSTH_unclustered, label='Unclustered', color=palette['Unclustered'])\n",
    "if encoding_mode == 1:\n",
    "    ax_psth.plot(bin_centers / 1000, ripple_PSTH_not_recalled, label='Not Recalled', color=palette['Not Recalled'])\n",
    "    ax_psth.axvline(x=0.0, color='black', linestyle='--')\n",
    "    ax_psth.axvline(x=1.6, color='black', linestyle='--')\n",
    "    ax_psth.set_xlim(-0.25, 2.05)\n",
    "elif encoding_mode == 0:\n",
    "    ax_psth.set_xlim(-2.0, 2.0)\n",
    "ax_psth.set_xlabel('Time (s)')\n",
    "ax_psth.set_ylim(0,bar_ylimits[1])\n",
    "ax_psth.set_ylabel('Ripple rate (Hz)')\n",
    "ax_psth.spines['right'].set_visible(False)\n",
    "ax_psth.spines['top'].set_visible(False)\n",
    "\n",
    "# Add legend to the bottom plot\n",
    "ax_psth.legend(loc='upper center', frameon=False)\n",
    "\n",
    "# Adjust layout\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "a=1;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1f31b99-b050-4760-9327-ee4cad3d6c4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels.api as sm\n",
    "from statsmodels.formula.api import mixedlm\n",
    "\n",
    "# Flatten the ripple data for easier modeling\n",
    "ripple_data = start_array[:, ripple_swarm_start:ripple_swarm_end].sum(axis=1)\n",
    "\n",
    "# Create a DataFrame with the data\n",
    "df = pd.DataFrame({\n",
    "    'ripple_rate': ripple_data,\n",
    "    'clust_clustered': (sub_clust_ID > 1).astype(int),\n",
    "    'clust_unclustered': (sub_clust_ID < 0).astype(int),\n",
    "    'clust_not_recalled': (sub_clust_ID == 0).astype(int),\n",
    "    'session': dd_trials['sess'][final_sub_idxs],\n",
    "    'subject': dd_trials['subj'][final_sub_idxs],\n",
    "    'low_gamma': z_low_gamma_trials,\n",
    "})\n",
    "if remove_low_freq == 2:\n",
    "    df['high_gamma'] = z_high_gamma_trials\n",
    "\n",
    "# Define the model formula\n",
    "# 'ripple_rate ~ clust_clustered + clust_unclustered + clust_not_recalled' specifies the fixed effects\n",
    "# '(1 | subject/session)' specifies the random effects, with session nested within subject\n",
    "if encoding_mode == 1:\n",
    "    formula = \"ripple_rate ~ clust_clustered + clust_unclustered\"\n",
    "elif encoding_mode == 0:\n",
    "    formula = \"ripple_rate ~ clust_clustered\" # since not recalled doesn't exist\n",
    "model = mixedlm(\n",
    "    formula=formula,data=df, groups=df[\"subject\"], vc_formula={\"session\": \"0 + session\"})\n",
    "\n",
    "print(model.fit().summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b575e2f8-aedc-408b-868a-59d37214aff4",
   "metadata": {},
   "outputs": [],
   "source": [
    "if encoding_mode == 1:\n",
    "    if remove_low_freq == 1:\n",
    "        formula = \"ripple_rate ~ low_gamma*(clust_clustered + clust_unclustered)\"\n",
    "    elif remove_low_freq == 2:\n",
    "        formula = \"ripple_rate ~ high_gamma*(clust_clustered + clust_unclustered)\"\n",
    "elif encoding_mode == 0:\n",
    "    if remove_low_freq == 1:\n",
    "        formula = \"ripple_rate ~ low_gamma*clust_clustered\" # since not recalled doesn't exist\n",
    "    elif remove_low_freq == 2:\n",
    "        formula = \"ripple_rate ~ high_gamma*clust_clustered\" # since not recalled doesn't exist\n",
    "model = mixedlm(\n",
    "    formula=formula,data=df, groups=df[\"subject\"], vc_formula={\"session\": \"0 + session\"})\n",
    "\n",
    "print(model.fit().summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23c20a39-afb1-4310-bf8f-fd18f940ed94",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bdb39c1-2633-4f75-a9f3-914dafaaf7a5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "workshopJ",
   "language": "python",
   "name": "workshopj"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
