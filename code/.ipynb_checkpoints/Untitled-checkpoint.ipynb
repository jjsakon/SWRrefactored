{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "03ee74d8-4cca-4458-be5c-0156bff651c5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pandas(Index=1774, Recognition=nan, all_events='protocols/r1/subjects/R1345D/experiments/FR1/sessions/0/behavioral/current_processed/all_events.json', contacts='protocols/r1/subjects/R1345D/localizations/0/montages/0/neuroradiology/current_processed/contacts.json', experiment='FR1', import_type='build', localization=0, math_events='protocols/r1/subjects/R1345D/experiments/FR1/sessions/0/behavioral/current_processed/math_events.json', montage=0, original_experiment=nan, original_session=nan, pairs='protocols/r1/subjects/R1345D/localizations/0/montages/0/neuroradiology/current_processed/pairs.json', ps4_events=nan, session=0, subject='R1345D', subject_alias='R1345D', system_version=3.1, task_events='protocols/r1/subjects/R1345D/experiments/FR1/sessions/0/behavioral/current_processed/task_events.json')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd; pd.set_option('display.max_columns', 30)\n",
    "import numpy as np\n",
    "from cmlreaders import CMLReader, get_data_index\n",
    "import ptsa\n",
    "import sys\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from pylab import *\n",
    "from copy import copy\n",
    "from scipy import stats\n",
    "plt.rcParams['pdf.fonttype'] = 42; plt.rcParams['ps.fonttype'] = 42 # fix fonts for Illustrator\n",
    "sys.path.append('/home1/john/SWRrefactored/code/SWR_modules/')\n",
    "from SWRmodule import *\n",
    "from general import * #superVstack,findInd,findAinB\n",
    "import csv\n",
    "import os\n",
    "import dill, pickle\n",
    "import mne\n",
    "from copy import copy    \n",
    "from scipy.signal import firwin,filtfilt,kaiserord\n",
    "from ptsa.data.filters import ButterworthFilter, ResampleFilter, MorletWaveletFilter\n",
    "import xarray as xarray\n",
    "from brain_labels import HPC_labels, ENT_labels, PHC_labels, temporal_lobe_labels,\\\n",
    "                        MFG_labels, IFG_labels, nonHPC_MTL_labels, ENTPHC_labels, AMY_labels\n",
    "# from SWRmodule import CMLReadDFRow,get_bp_tal_struct,get_elec_regions,ptsa_to_mne,detectRipplesHamming\n",
    "# from SWRmodule import *\n",
    "# downsampleBinary,LogDFExceptionLine,getBadChannels,getStartEndArrays,getSecondRecalls,\\\n",
    "#                     removeRepeatedRecalls,getSWRpathInfo,selectRecallType,correctEEGoffset,\\\n",
    "#                     getSerialposOfRecalls,getElectrodeRanges,\\\n",
    "#                     detectRipplesHamming,detectRipplesButter,getRetrievalStartAlignmentCorrection,\\\n",
    "#                     removeRepeatsBySerialpos,get_recall_clustering, compute_morlet # specific to clustering\n",
    "\n",
    "import pingouin as pg\n",
    "\n",
    "################################################################\n",
    "df = get_data_index(\"r1\") # all RAM subjects\n",
    "exp = 'FR1' # 'catFR1' #'FR1'\n",
    "save_path = f'/scratch/john/SWRrefactored/patient_info/{exp}/'\n",
    "### params that clusterRun used\n",
    "selected_period = 'encoding' # surrounding_recall # whole_retrieval # encoding \n",
    "recall_type_switch = 10 # 0 for original, 1 for only those with subsequent, 2 for second recalls only, 3 for isolated recalls\n",
    "remove_soz_ictal = 0\n",
    "recall_minimum = 2000\n",
    "filter_type = 'hamming'\n",
    "extra = '' #'- ZERO_IRI'\n",
    "selected_patients = ['R1054J','R1345D','R1048E','R1328E','R1308T', # first 2 are sr â‰¥ 1000. 3rd is 500 Hz.\n",
    "    'R1137E','R1136N','R1094T','R1122E','R1385E'] #[\"R1313J\", \"R1286J\", \"R1275D\", \"R1330D\", \"R1138T\", \"R1067P\", \"R1174T\", \"R1066P\"]\n",
    "available_regions = [HPC_labels] #, ENTPHC_labels, AMY_labels]\n",
    "brain_region_idxs = np.arange(len(available_regions))\n",
    "################################################################\n",
    "     \n",
    "    \n",
    "selected_region = 'HPC'    \n",
    "region_name = 'HPC'\n",
    "temp_df_select = 'R1345D'\n",
    "    \n",
    "### params that clusterRun used\n",
    "recall_type_switch = 10 # 0 for original, 1 for only those with subsequent, 2 for second recalls only, 3 for isolated recalls\n",
    "remove_soz_ictal = 0\n",
    "filter_type = 'hamming'\n",
    "extra = '' #'-ZERO_IRI'\n",
    "\n",
    "### PARAMS ###\n",
    "\n",
    "##\n",
    "## NOTE: for looking at individual lags make sure min_recalls is set to 0 or will eliminate trials from low recall lists\n",
    "##\n",
    "\n",
    "save_values = 1\n",
    "\n",
    "# there are three periods this code is set up to look at: periods aligned to recall, the entire retrieval period, and the encoding period\n",
    "  # switch to determine which recalls to look at! (see details below)\n",
    "# (as of 2021 always leave this as 0, since I select for 4/6/etc below)\n",
    "# 0: Original analysis taking only recalls without a recall in 2 s IRI before them\n",
    "# 1: Take these same recalls, but keep only those WITH a recall within 2 s after they occur \n",
    "# 2: test condition where we look at second recalls within IRI ONLY (there is an initial recall in 2 s before current recall)\n",
    "# 3: isolated recalls with no other recalls +/- RECALL_MINIMUM s\n",
    "# 4: only first recall of every retrieval period\n",
    "# 5: take only those recalls that come second in retrieval period within 2 s of first retrieval\n",
    "# 6: take only NOT first recall of every retrieval period\n",
    "# 7: take only NOT first recall AND ISOLATED trials (this should REALLY maximize SWR bump)\n",
    "# 10: same as 0 but with no IRI (mostly just to see number of recalls)\n",
    "remove_soz_ictal = 0 # 0 for nothing, 1 for SOZ, 2 for SOZ+ictal    \n",
    "min_ripple_rate = 0.1 # Hz.\n",
    "max_ripple_rate = 1.5 # Hz.\n",
    "max_trial_by_trial_correlation = 0.05 # if ripples correlated more than this remove them\n",
    "max_electrode_by_electrode_correlation = 0.2\n",
    "\n",
    "### semantic/temporal clustering parameters ###\n",
    "min_recalls = 0\n",
    "PCA_ndim = 1 # number of PC dims to use for semantic clustering (Ethan usually found only 1 worked for theta/FC)\n",
    "\n",
    "#     # for parametric run through recall_minimums\n",
    "#         recall_mins = np.arange(800,5100,100) #[800,900,1100,1200,1300,1400]\n",
    "# #     recall_mins = [1600,1700,1800,1900,2100,2200,2300,2400,2500,2600,2700,2800,2900,3000]\n",
    "#     for recall_minimum in recall_mins:\n",
    "\n",
    "# recall params\n",
    "recall_minimum = 2000 # for isolated recalls what is minimum time for recall to be considered isolated?\n",
    "IRI = 2000 # inter-ripple interval...remove ripples within this range (keep only first one and remove those after it)\n",
    "retrieval_whole_time = 10000\n",
    "# encoding params\n",
    "encoding_time = 2300 # actual preentation is 1.6 s + 0.75-1.0 s so keep +700 ms so can plot +500 ms\n",
    "pre_encoding_time = -700 # since minimum ISI is 0.75 s let's only plot the 500 ms before word on with a 200 ms buffer\n",
    "# these aren't likely to be changed:\n",
    "desired_sample_rate = 500. # in Hz. This seems like lowerst common denominator recording freq.\n",
    "eeg_buffer = 1000 # buffer to add to either end of IRI when processing eeg #**\n",
    "filter_type = 'hamming' # see local version below for details. 'butter' is removed from cluster version so don't change this    \n",
    "### END PARAMS ###    \n",
    "\n",
    "\n",
    "if selected_period == 'surrounding_recall':\n",
    "    if IRI == 0:\n",
    "        psth_start = -2000\n",
    "        psth_end = 2000\n",
    "    else:\n",
    "        psth_start = -IRI # only makes sense to look at period <= IRI\n",
    "        psth_end = IRI # how long to grab data after recall\n",
    "elif selected_period == 'whole_retrieval':\n",
    "    psth_start = -IRI # doesn't have to be IRI just 2000 ms is convenient\n",
    "    psth_end = IRI+retrieval_whole_time\n",
    "elif selected_period == 'encoding':\n",
    "    psth_start = pre_encoding_time\n",
    "    psth_end = encoding_time\n",
    "\n",
    "# ripple_array = []; fr_array = []; \n",
    "# trial_nums = []; \n",
    "# elec_names = []; sub_sess_names = []; sub_names = []\n",
    "# electrodes_per_session = []\n",
    "# total_lists = 0; total_recalls = 0; kept_recalls = 0\n",
    "# align_adjust = 0\n",
    "# ent_elec_ct = []; sd_regions = []; not_sd_regions = []\n",
    "# ripple_ied_accum_ct = []\n",
    "# time_add_save = []\n",
    "# encoded_word_key_array = []; category_array = []\n",
    "\n",
    "# session_ripple_rate_by_elec = []; # for cluster version only since I compare across electrodes for each session\n",
    "\n",
    "# list_recall_num_array = []; rectime_array = []; # new ones added 2020-11-24\n",
    "# serialpos_array = [] # used to be encoding info but commandeered for surrounding_recalls ~~~\n",
    "# recall_position_array = []\n",
    "# session_events = pd.DataFrame()\n",
    "\n",
    "# trial_by_trial_correlation = []; elec_by_elec_correlation = []\n",
    "# elec_ripple_rate_array = []\n",
    "# channel_coords = []; electrode_labels = []\n",
    "\n",
    "# semantic_clustering_key = []\n",
    "# temporal_clustering_key = []\n",
    "# semantic_clustering_from_key = []\n",
    "# serialpos_lags = []; serialpos_from_lags = []; CRP_lags = []\n",
    "# list_trial_nums = []; list_num_key = []\n",
    "# list_level_semantic = []; list_level_temporal = []\n",
    "\n",
    "program_ran = 0\n",
    "\n",
    "with open(f'/scratch/john/SWRrefactored/patient_info/temp_dfSWR_{region_name}_{selected_period}_{exp}.p', 'rb') as f: ### change here to avoid overwrite\n",
    "    temp_df = dill.load(f)\n",
    "\n",
    "row = None\n",
    "# if temp_df_select is a patient id, then loop through the available patients\n",
    "# until the selected patient id is found and retrieve the row in temp_df\n",
    "# corresponidng to the selected patient\n",
    "if isinstance(temp_df_select, str):\n",
    "    for r in temp_df:\n",
    "        if temp_df_select == r.subject:\n",
    "            row = r\n",
    "            break\n",
    "\n",
    "elif isinstance(temp_df_select, int):\n",
    "    row = temp_df[temp_df_select]\n",
    "    \n",
    "row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f94c7e2f-f6e8-44ea-aa2e-51434f08ce42",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env1",
   "language": "python",
   "name": "env1"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
