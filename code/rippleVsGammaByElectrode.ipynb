{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fc17f345-6597-4a33-8ed8-1b3b07d4e1c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload\n",
    "\n",
    "import pandas as pd; pd.set_option('display.max_columns', 30)\n",
    "import numpy as np\n",
    "from cmlreaders import CMLReader, get_data_index\n",
    "import ptsa\n",
    "import sys\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sb\n",
    "from pylab import *\n",
    "from copy import copy\n",
    "from scipy import stats\n",
    "plt.rcParams['pdf.fonttype'] = 42; plt.rcParams['ps.fonttype'] = 42 # fix fonts for Illustrator\n",
    "sys.path.append('/home1/john/SWRrefactored/code/SWR_modules/')\n",
    "from SWRmodule import *\n",
    "from general import * #superVstack,findInd,findAinB\n",
    "from power_functions import z_score, process_power, load_z_scored_power\n",
    "\n",
    "base = '/home1/john/SWRrefactored'\n",
    "sys.path.append(f'{base}/code/')\n",
    "\n",
    "from load_data_numpy import load_data_np\n",
    "from SWRmodule import triangleSmooth\n",
    "# from comodulogram import remove_session_string, get_filtered_signal\n",
    "# from fooof import FOOOF\n",
    "\n",
    "import statsmodels.formula.api as smf\n",
    "from scipy.signal import decimate, resample, hilbert, welch, spectrogram\n",
    "from mne.time_frequency import tfr_array_morlet\n",
    "\n",
    "# # Import the time & event model objects and Bands object to manage oscillation band definitions\n",
    "# from specparam import SpectralTimeModel, SpectralTimeEventModel, Bands\n",
    "# # Import helper utilities for simulating and plotting spectrograms\n",
    "# from specparam.sim import sim_spectrogram\n",
    "# from specparam.plts.spectra import plot_spectrogram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "5846d65a-6e2d-4517-a199-5519e465efa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for now the plotting code only works with one region at a time\n",
    "region_name = ['HPC'] # ['ENT'] # ['AMY'] ['HPC']\n",
    "subregion = ['ca1'] #['ca1'] # can use [''] to select ALL subregions\n",
    "task = 'catFR1' # 'catFR1'\n",
    "savePath = f'{base}/figures/'\n",
    "\n",
    "# 1 for encoding, 0 for recall\n",
    "encoding_mode_arr = [1] #[0,1] \n",
    "freq_range_str_arr = [[33.5,75]]#,[80,120]] #[[33.5,75],[80,120]] #,[2,4],[7,9]] # [80,178]\n",
    "# these were selecetd to avoid 60 and 120 Hz using np.logspace(np.log10(30),np.log10(75),10)\n",
    "\n",
    "fs = 500 # sampling rate for raw data and ripples from createEventsForDF.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "105c8ab8-3da0-405c-921b-f9ae99143a46",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data\n",
      "LOADING DATA FROM: HPC FOR EXPERIMENT catFR1\n",
      "order: C\n",
      "Generating figures for run_mode:  1\n"
     ]
    }
   ],
   "source": [
    "for encoding_mode in encoding_mode_arr:\n",
    "\n",
    "    dd_trials = load_data_np(encoding_mode,task,\n",
    "        region_name=region_name, train_only=False, subregion=subregion)\n",
    "\n",
    "    region_str = region_name[0]\n",
    "    subregion_str = subregion[0]\n",
    "    \n",
    "    clust = dd_trials['clust_int']\n",
    "    \n",
    "    start_cutoff = 0 # in samples\n",
    "    if encoding_mode == 1: # raw is from -1.7 to 3.3 s from word_on\n",
    "        saveName = 'encoding_'\n",
    "        recall_str = ''\n",
    "        correct = dd_trials['correct']\n",
    "        incorrect_idxs = np.argwhere(correct==0).squeeze()\n",
    "        end_cutoff = 2500 # just take the whole range of data to better estimate Morlet     \n",
    " \n",
    "    elif encoding_mode == 0: # raw is from -3 to 3 s from recall\n",
    "        saveName = 'recall_'\n",
    "        recall_str = '_recall'\n",
    "        end_cutoff = 3000 # just take the whole range of data to better estimate Morlet       \n",
    "\n",
    "    sr_factor = 1000/fs\n",
    "    \n",
    "    print(\"Generating figures for run_mode: \", encoding_mode)\n",
    "    # starts with high and moves to low\n",
    "    power_z = load_z_scored_power(dd_trials, freq_range_str_arr, encoding_mode,fs,start_cutoff, end_cutoff)\n",
    "        \n",
    "    # note that output is 50 Hz (20 ms bins) since started 500 hz and decimated 10x\n",
    "    if len(subregion[0]) > 0:\n",
    "        subregion_str = f'_{subregion[0]}'\n",
    "    else:\n",
    "        subregion_str = ''           \n",
    "\n",
    "a=1;            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "306ee27f-6e67-4b7d-8287-69622a8cca9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# info\n",
    "dd_trials.keys()\n",
    "np.shape(dd_trials['ripple'])\n",
    "np.shape(dd_trials['raw'])\n",
    "\n",
    "np.shape(power_z)\n",
    "freq_range_str_arr\n",
    "\n",
    "unique_subs = np.unique(dd_trials['subj'])\n",
    "unique_subs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c8960e2-8765-4f83-9a75-ad842b2c1c6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "gamma_sd_thresh = 1.5\n",
    "remove_first_recalls = 0 # if looking at recall might want to remove first recall of each list\n",
    "\n",
    "# select a patient?\n",
    "patient_idx = -1 # -1 means all\n",
    "\n",
    "if patient_idx >-1: \n",
    "    sub_idxs = dd_trials['subj']==unique_subs[patient_idx]\n",
    "else:\n",
    "    sub_idxs = np.ones(len(dd_trials['subj']),dtype=bool)\n",
    "print(f'Number of trials: {sum(sub_idxs)} from the following subs:')\n",
    "np.unique(dd_trials['subj'][sub_idxs])\n",
    "\n",
    "# if recalls remove the intrusions\n",
    "if encoding_mode == 0:\n",
    "    if remove_first_recalls:\n",
    "        final_sub_idxs = (sub_idxs) & (clust!=0) & (dd_trials['recall_pos']!=1)\n",
    "    else:\n",
    "        final_sub_idxs = (sub_idxs) & (clust!=0)\n",
    "else:\n",
    "    final_sub_idxs = sub_idxs\n",
    "      \n",
    "# update each variable with indices\n",
    "sub_ripples = dd_trials['ripple'][final_sub_idxs] # ripples are detected from -0.7 to 2.3 s @ 500 Hz\n",
    "if power_z.ndim == 2:\n",
    "    power_z = power_z[np.newaxis, :, :]\n",
    "sub_Zs = power_z[:,final_sub_idxs,:]\n",
    "sub_clust_ID = clust[final_sub_idxs]\n",
    "np.shape(sub_Zs)\n",
    "\n",
    "z_factor = sr_factor*10 # z_score was decimated 10x\n",
    "if encoding_mode == 1:\n",
    "    ripple_start_offset = -700 # ripple_trials go from -0.7 to 2.3 s (no buffers)\n",
    "    ripple_analysis_start = 300 # time in ms\n",
    "    ripple_analysis_end = 1300 # time in ms\n",
    "    \n",
    "    # average z-score over time for same range as ripples\n",
    "    gamma_time_range = slice(int((1700+ripple_analysis_start)/z_factor),int((1700+ripple_analysis_end)/z_factor)) # +1700 since goes from -1.7 to 3.3 s   \n",
    "    \n",
    "elif encoding_mode == 0:\n",
    "    ripple_start_offset = -2000 # ripple matrix 2000 ms on either side of recall\n",
    "    ripple_analysis_start = -1900 # time in ms\n",
    "    ripple_analysis_end = -100 # time in ms    \n",
    "\n",
    "    # average z-score over time for same range as ripples\n",
    "    gamma_time_range = slice(int((3000+ripple_analysis_start)/z_factor),int((3000+ripple_analysis_end)/z_factor)) # +3000 since goes from -3 to 3 s\n",
    "\n",
    "# check power > thresh in gamma time range\n",
    "z_low_gamma_trials = np.mean(sub_Zs[0,:,gamma_time_range],1)>gamma_sd_thresh\n",
    "if np.shape(sub_Zs)[0]>1:\n",
    "    z_high_gamma_trials = np.mean(sub_Zs[1,:,gamma_time_range],1)>gamma_sd_thresh     \n",
    "    \n",
    "ripple_trials = np.sum(sub_ripples[:,int((-ripple_start_offset+ripple_analysis_start)/sr_factor):\n",
    "                                   int((-ripple_start_offset+ripple_analysis_end)/sr_factor)],1)>0\n",
    "print(f'{sum(ripple_trials)} trials have ripples which is {np.round(100*sum(ripple_trials)/sum(final_sub_idxs),2)}% of total')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c54752e1-4be1-4a56-b8b2-b6e54439b11a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"{len(np.unique(dd_trials['elec_labels'][sub_idxs]))} elecs\")\n",
    "print(f\"from {len(np.unique(dd_trials['sess'][sub_idxs]))} sessions\")\n",
    "print(f\"from {len(np.unique(dd_trials['subj'][sub_idxs]))} patients\")\n",
    "\n",
    "if region_name == ['ENT']:\n",
    "    ENT_sess = np.unique(dd_trials['sess'][sub_idxs])\n",
    "    ENT_sub = np.unique(dd_trials['subj'][sub_idxs])\n",
    "elif region_name == ['HPC']:\n",
    "    HPC_sess = np.unique(dd_trials['sess'][sub_idxs])\n",
    "    HPC_sub = np.unique(dd_trials['subj'][sub_idxs])\n",
    "elif region_name == ['AMY']:\n",
    "    AMY_sess = np.unique(dd_trials['sess'][sub_idxs])\n",
    "    AMY_sub = np.unique(dd_trials['subj'][sub_idxs])\n",
    "    \n",
    "save_sub_sess_info = 0\n",
    "\n",
    "if save_sub_sess_info == 1:\n",
    "    import pickle\n",
    "    with open('../misc/region_data.pkl', 'wb') as f:\n",
    "        pickle.dump({\n",
    "            'ENT_sess': ENT_sess,\n",
    "            'ENT_sub': ENT_sub,\n",
    "            'HPC_sess': HPC_sess,\n",
    "            'HPC_sub': HPC_sub,\n",
    "            'AMY_sess': AMY_sess,\n",
    "            'AMY_sub': AMY_sub\n",
    "        }, f)   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d257ae37-ab00-486a-a01d-ecf5dbf9a760",
   "metadata": {},
   "source": [
    "### get start_array!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91bd71fd-020f-4985-8a10-0265b3150f18",
   "metadata": {},
   "outputs": [],
   "source": [
    "start_array,_ = getStartEndArrays(sub_ripples)\n",
    "\n",
    "# first bin has artificially high number due to how start_srray works\n",
    "start_array = start_array[:,1:] \n",
    "print(f'start array shape: {np.shape(start_array)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc7943b0-39ee-4d86-bcd5-a0741df700c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "dd_trials['elec_labels']\n",
    "len(dd_trials['elec_labels'][final_sub_idxs])\n",
    "len(dd_trials['subj'][final_sub_idxs])\n",
    "len(dd_trials['sess'][final_sub_idxs])\n",
    "np.shape(sub_Zs)\n",
    "len(sub_clust_ID)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9df4470a-d15f-4f48-a0c6-5e4a43915b42",
   "metadata": {},
   "source": [
    "# plot ripples v. gamma by elec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ceeb4c1-d3fb-4f8e-b2fd-0a4748bd8b12",
   "metadata": {},
   "outputs": [],
   "source": [
    "min_recalls = 25\n",
    "min_clust_recalls = 10\n",
    "\n",
    "ripple_time_range = slice( int((-ripple_start_offset+ripple_analysis_start)/sr_factor),\n",
    "                        int((-ripple_start_offset+ripple_analysis_end)/sr_factor) )\n",
    "# basically *500 sr divided by 1.8 sec\n",
    "ripple_hz_conv_factor = (1000/sr_factor) / (sr_factor*(ripple_time_range.stop-ripple_time_range.start)/1000)\n",
    "\n",
    "sub_elec_labels = dd_trials['elec_labels'][final_sub_idxs]\n",
    "unique_elecs = np.unique(sub_elec_labels)\n",
    "\n",
    "# find gamma and ripple rates\n",
    "sub_ripple_elecs = []; sub_low_gamma_elecs = []; sub_high_gamma_elecs = []\n",
    "sub_ripple_elecs_clust_diff = []; sub_low_gamma_elecs_clust_diff = []; sub_high_gamma_elecs_clust_diff = []\n",
    "min_trial_elecs = []\n",
    "min_trial_clust_elec = []\n",
    "for elec in unique_elecs:\n",
    "    elec_idxs = sub_elec_labels==elec\n",
    "    if sum(elec_idxs) >= min_recalls:\n",
    "        min_trial_elecs.append(elec)\n",
    "        sub_ripple_elecs.append(ripple_hz_conv_factor*np.mean(start_array[elec_idxs,ripple_time_range]))\n",
    "        sub_low_gamma_elecs.append(np.mean(sub_Zs[0,elec_idxs,gamma_time_range]))\n",
    "        if len(sub_Zs) == 1: # just duplicate it so it doesn't crash...will just repeat the plot        \n",
    "            sub_high_gamma_elecs.append(np.mean(sub_Zs[0,elec_idxs,gamma_time_range]))        \n",
    "        else:\n",
    "            sub_high_gamma_elecs.append(np.mean(sub_Zs[1,elec_idxs,gamma_time_range]))        \n",
    "\n",
    "        # same but let's find diff b/w clust and unclust recalls\n",
    "        sub_elec_clust_ID = sub_clust_ID[elec_idxs]\n",
    "        elec_clustered_full_scope = elec_idxs & (sub_clust_ID>1)\n",
    "        elec_unclustered_full_scope = elec_idxs & (sub_clust_ID<0)        \n",
    "        if (sum(sub_elec_clust_ID>1)>=min_clust_recalls) & (sum(sub_elec_clust_ID<0)>=min_clust_recalls):\n",
    "            min_trial_clust_elec.append(elec)            \n",
    "            sub_ripple_elecs_clust_diff.append( ripple_hz_conv_factor*\\\n",
    "                                ( np.mean(start_array[elec_clustered_full_scope,ripple_time_range]) - \\\n",
    "                                np.mean(start_array[elec_unclustered_full_scope,ripple_time_range]) ) )\n",
    "            sub_low_gamma_elecs_clust_diff.append( np.mean(sub_Zs[0,elec_clustered_full_scope,gamma_time_range]) - \\\n",
    "                                                   np.mean(sub_Zs[0,elec_unclustered_full_scope,gamma_time_range]) )\n",
    "            if len(sub_Zs) == 1: # just duplicate it so it doesn't crash...will just repeat the plot\n",
    "                sub_high_gamma_elecs_clust_diff.append( np.mean(sub_Zs[0,elec_clustered_full_scope,gamma_time_range]) - \\\n",
    "                                                   np.mean(sub_Zs[0,elec_unclustered_full_scope,gamma_time_range]) ) \n",
    "            else:\n",
    "                sub_high_gamma_elecs_clust_diff.append( np.mean(sub_Zs[1,elec_clustered_full_scope,gamma_time_range]) - \\\n",
    "                                                   np.mean(sub_Zs[1,elec_unclustered_full_scope,gamma_time_range]) )       \n",
    "        \n",
    "print(f'{len(min_trial_elecs)} of {len(unique_elecs)} elecs survive {min_recalls} min_recalls')\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "134fd192-8070-4cdc-914d-fdfa2491914d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import pearsonr\n",
    "\n",
    "num_sd_line = 0.5  # Adjust this value to change the number of SDs\n",
    "xlim = [-1.5,1.1]\n",
    "\n",
    "# low gamma vs. ripple rate\n",
    "correlation_coefficient, p_value = pearsonr(sub_low_gamma_elecs, sub_ripple_elecs)\n",
    "\n",
    "plt.scatter(sub_low_gamma_elecs, sub_ripple_elecs)\n",
    "plt.title(\"Low Gamma vs. Ripple rate\")\n",
    "annotation_text = f\"r = {correlation_coefficient:.2f}\\np = {p_value:.2e}\"\n",
    "\n",
    "# Fit a linear regression line and plot it\n",
    "slope, intercept = np.polyfit(sub_low_gamma_elecs, sub_ripple_elecs, 1)\n",
    "fit_line = np.array(sub_low_gamma_elecs) * slope + intercept\n",
    "# plt.plot(sub_low_gamma_elecs, fit_line, color='red', linestyle='--', label='Linear fit')\n",
    "plt.annotate(annotation_text, xy=(0.05, 0.95), xycoords='axes fraction', \n",
    "             fontsize=12, verticalalignment='top')\n",
    "\n",
    "# Calculate the mean and standard deviation for both variables\n",
    "mean_low_gamma = np.mean(sub_low_gamma_elecs)\n",
    "std_low_gamma = np.std(sub_low_gamma_elecs)\n",
    "mean_ripple = np.mean(sub_ripple_elecs)\n",
    "std_ripple = np.std(sub_ripple_elecs)\n",
    "\n",
    "# Plot the ±num_sd_line lines for sub_low_gamma_elecs\n",
    "ylim = plt.ylim()\n",
    "plt.axvline(mean_low_gamma + num_sd_line * std_low_gamma, color='blue', linestyle=':', label=f'+{num_sd_line} SD Low Gamma')\n",
    "plt.text(mean_low_gamma + num_sd_line * std_low_gamma, ylim[1] - (ylim[1] - ylim[0]) * 0.05, \n",
    "         f'+{num_sd_line} SD', color='blue', ha='left', va='bottom')\n",
    "# plt.axvline(mean_low_gamma - num_sd_line * std_low_gamma, color='blue', linestyle=':', label=f'-{num_sd_line} SD Low Gamma')\n",
    "# plt.text(mean_low_gamma - num_sd_line * std_low_gamma, ylim[1] - (ylim[1] - ylim[0]) * 0.05, \n",
    "#          f'-{num_sd_line} SD', color='blue', ha='right', va='bottom')\n",
    "plt.axhline(mean_ripple + num_sd_line * std_ripple, color='green', linestyle=':', label=f'+{num_sd_line} SD Ripple')\n",
    "plt.text(plt.xlim()[1], mean_ripple + num_sd_line * std_ripple, f'+{num_sd_line} SD', color='green', ha='right', va='bottom')\n",
    "# plt.axhline(mean_ripple - num_sd_line * std_ripple, color='green', linestyle=':', label=f'-{num_sd_line} SD Ripple')\n",
    "# plt.text(plt.xlim()[1], mean_ripple - num_sd_line * std_ripple, f'-{num_sd_line} SD', color='green', ha='right', va='top')\n",
    "\n",
    "plt.xlabel('Low gamma power')\n",
    "plt.ylabel('Ripple rate')\n",
    "plt.xlim(xlim)\n",
    "plt.tight_layout(); plt.show()\n",
    "\n",
    "# high gamma vs. ripple rate\n",
    "correlation_coefficient, p_value = pearsonr(sub_high_gamma_elecs, sub_ripple_elecs)\n",
    "\n",
    "plt.scatter(sub_high_gamma_elecs, sub_ripple_elecs)\n",
    "plt.title(\"High Gamma vs. Ripple rate\")\n",
    "annotation_text = f\"r = {correlation_coefficient:.2f}\\np = {p_value:.2e}\"\n",
    "\n",
    "# Fit a linear regression line and plot it\n",
    "slope, intercept = np.polyfit(sub_high_gamma_elecs, sub_ripple_elecs, 1)\n",
    "fit_line = np.array(sub_high_gamma_elecs) * slope + intercept\n",
    "# plt.plot(sub_high_gamma_elecs, fit_line, color='red', linestyle='--', label='Linear fit')\n",
    "plt.annotate(annotation_text, xy=(0.05, 0.95), xycoords='axes fraction', \n",
    "             fontsize=12, verticalalignment='top')\n",
    "\n",
    "# Calculate the mean and standard deviation for both variables\n",
    "mean_high_gamma = np.mean(sub_high_gamma_elecs)\n",
    "std_high_gamma = np.std(sub_high_gamma_elecs)\n",
    "\n",
    "# Plot the ±num_sd_line lines for sub_low_gamma_elecs\n",
    "ylim = plt.ylim()\n",
    "plt.axvline(mean_high_gamma + num_sd_line * std_high_gamma, color='blue', linestyle=':', label=f'+{num_sd_line} SD Low Gamma')\n",
    "plt.text(mean_high_gamma + num_sd_line * std_high_gamma, ylim[1] - (ylim[1] - ylim[0]) * 0.05, \n",
    "         f'+{num_sd_line} SD', color='blue', ha='left', va='bottom')\n",
    "# plt.axvline(mean_high_gamma - num_sd_line * std_high_gamma, color='blue', linestyle=':', label=f'-{num_sd_line} SD Low Gamma')\n",
    "# plt.text(mean_high_gamma - num_sd_line * std_high_gamma, ylim[1] - (ylim[1] - ylim[0]) * 0.05, \n",
    "#          f'-{num_sd_line} SD', color='blue', ha='right', va='bottom')\n",
    "plt.axhline(mean_ripple + num_sd_line * std_ripple, color='green', linestyle=':', label=f'+{num_sd_line} SD Ripple')\n",
    "plt.text(plt.xlim()[1], mean_ripple + num_sd_line * std_ripple, f'+{num_sd_line} SD', color='green', ha='right', va='bottom')\n",
    "# plt.axhline(mean_ripple - num_sd_line * std_ripple, color='green', linestyle=':', label=f'-{num_sd_line} SD Ripple')\n",
    "# plt.text(plt.xlim()[1], mean_ripple - num_sd_line * std_ripple, f'-{num_sd_line} SD', color='green', ha='right', va='top')\n",
    "\n",
    "plt.xlabel('High gamma power')\n",
    "plt.ylabel('Ripple rate')\n",
    "plt.xlim(xlim)\n",
    "plt.tight_layout(); plt.show()\n",
    "\n",
    "a=1;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8400df40-3e96-45ed-b0ad-0fe012e007d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# delta(low gamma) vs. delta(ripple rate) (where both deltas are clust - unclust recalls)\n",
    "correlation_coefficient, p_value = pearsonr(sub_low_gamma_elecs_clust_diff, sub_ripple_elecs_clust_diff)\n",
    "\n",
    "plt.scatter(sub_low_gamma_elecs_clust_diff, sub_ripple_elecs_clust_diff)\n",
    "plt.title(r\"$\\Delta$Low Gamma vs. $\\Delta$Ripple rate\")\n",
    "annotation_text = f\"r = {correlation_coefficient:.2f}\\np = {p_value:.2e}\"\n",
    "plt.annotate(annotation_text, xy=(0.05, 0.95), xycoords='axes fraction', \n",
    "             fontsize=12, verticalalignment='top')\n",
    "# Fit a linear regression line and plot it\n",
    "slope, intercept = np.polyfit(sub_low_gamma_elecs_clust_diff, sub_ripple_elecs_clust_diff, 1)\n",
    "fit_line = np.array(sub_low_gamma_elecs_clust_diff) * slope + intercept\n",
    "plt.plot(sub_low_gamma_elecs_clust_diff, fit_line, color='red', linestyle='--', label='Linear fit')\n",
    "plt.tight_layout(); plt.show()\n",
    "\n",
    "# high gamma vs. ripple rate\n",
    "correlation_coefficient, p_value = pearsonr(sub_high_gamma_elecs_clust_diff, sub_ripple_elecs_clust_diff)\n",
    "\n",
    "plt.scatter(sub_high_gamma_elecs_clust_diff, sub_ripple_elecs_clust_diff)\n",
    "plt.title(r\"$\\Delta$High Gamma vs. $\\Delta$Ripple rate\")\n",
    "annotation_text = f\"r = {correlation_coefficient:.2f}\\np = {p_value:.2e}\"\n",
    "plt.annotate(annotation_text, xy=(0.05, 0.95), xycoords='axes fraction', \n",
    "             fontsize=12, verticalalignment='top')\n",
    "# Fit a linear regression line and plot it\n",
    "slope, intercept = np.polyfit(sub_high_gamma_elecs_clust_diff, sub_ripple_elecs_clust_diff, 1)\n",
    "fit_line = np.array(sub_high_gamma_elecs_clust_diff) * slope + intercept\n",
    "plt.plot(sub_high_gamma_elecs_clust_diff, fit_line, color='red', linestyle='--', label='Linear fit')\n",
    "plt.tight_layout(); plt.show()\n",
    "\n",
    "a=1;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "053847b2-fd5c-4a9a-828a-066b635e9ad4",
   "metadata": {},
   "outputs": [],
   "source": [
    "remove_low_freq = 1 # 1 for low gamma/theta; 2 for high gamma/theta"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b8b3f33-dc02-4cd3-9c82-cd220456ddca",
   "metadata": {},
   "source": [
    "# ripples after removing low gamma trials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5e8de0a-f33e-40dd-a9fb-7c77eb485820",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.gridspec as gridspec\n",
    "\n",
    "# Function parameters\n",
    "bin_size = 100  # in ms\n",
    "smoothing_triangle = 5  # triangular smoothing window width\n",
    "\n",
    "bar_ylimits = (0, 0.42)\n",
    "\n",
    "if remove_low_freq == 1:\n",
    "    trial_select = ~z_low_gamma_trials\n",
    "elif remove_low_freq == 2:\n",
    "    trial_select = ~z_high_gamma_trials\n",
    "else:\n",
    "    print('Invalid remove_low_freq selection')\n",
    "    error    \n",
    "\n",
    "ripple_swarm_start = int((-ripple_start_offset+ripple_analysis_start)/sr_factor)\n",
    "ripple_swarm_end = int((-ripple_start_offset+ripple_analysis_end)/sr_factor)\n",
    "ripple_swarm_duration = (ripple_analysis_end-ripple_analysis_start)/1000  # convert to seconds\n",
    "\n",
    "# Apply the clust variable to split data into clustered, unclustered, and not recalled\n",
    "clust_clustered = sub_clust_ID > 1\n",
    "clust_unclustered = sub_clust_ID < 0\n",
    "clust_not_recalled = sub_clust_ID == 0\n",
    "\n",
    "# Calculate ripple means and standard errors for each condition\n",
    "mean_ripple_clustered = np.sum(start_array[trial_select & clust_clustered, ripple_swarm_start:ripple_swarm_end], axis=1) / ripple_swarm_duration\n",
    "mean_ripple_unclustered = np.sum(start_array[trial_select & clust_unclustered, ripple_swarm_start:ripple_swarm_end], axis=1) / ripple_swarm_duration\n",
    "mean_ripple_not_recalled = np.sum(start_array[trial_select & clust_not_recalled, ripple_swarm_start:ripple_swarm_end], axis=1) / ripple_swarm_duration\n",
    "\n",
    "if encoding_mode == 1:\n",
    "    means = [np.mean(mean_ripple_clustered), np.mean(mean_ripple_unclustered), np.mean(mean_ripple_not_recalled)]\n",
    "    ses = [np.std(mean_ripple_clustered) / np.sqrt(len(mean_ripple_clustered)),\n",
    "           np.std(mean_ripple_unclustered) / np.sqrt(len(mean_ripple_unclustered)),\n",
    "           np.std(mean_ripple_not_recalled) / np.sqrt(len(mean_ripple_not_recalled))]\n",
    "    fig = plt.figure(figsize=(4, 5))\n",
    "elif encoding_mode == 0:\n",
    "    means = [np.mean(mean_ripple_clustered), np.mean(mean_ripple_unclustered)]\n",
    "    ses = [np.std(mean_ripple_clustered) / np.sqrt(len(mean_ripple_clustered)),\n",
    "           np.std(mean_ripple_unclustered) / np.sqrt(len(mean_ripple_unclustered))]    \n",
    "    fig = plt.figure(figsize=(3, 5))\n",
    "\n",
    "# Define the palette for colors\n",
    "palette = {\n",
    "    'Clustered': 'blue',\n",
    "    'Unclustered': 'orange',\n",
    "    'Not Recalled': 'green'\n",
    "}\n",
    "\n",
    "# Set up the figure with GridSpec\n",
    "gs = gridspec.GridSpec(2, 3, height_ratios=[2, 2], width_ratios=[3, 3, 3])\n",
    "\n",
    "# Create the bar plot with error bars (span all columns)\n",
    "ax_bar = fig.add_subplot(gs[0, :])\n",
    "if encoding_mode == 1:\n",
    "    xlabels = ['Clustered', 'Unclustered', 'Not Recalled']\n",
    "    xcolors = [palette['Clustered'], palette['Unclustered'], palette['Not Recalled']]\n",
    "elif encoding_mode == 0:\n",
    "    xlabels = ['Clustered', 'Unclustered']\n",
    "    xcolors = [palette['Clustered'], palette['Unclustered']]\n",
    "bars = ax_bar.bar(x=xlabels, \n",
    "                  height=means, \n",
    "                  color=xcolors, \n",
    "                  yerr=ses, \n",
    "                  width=0.5,  # Adjust width to make bars tighter\n",
    "                  capsize=5, \n",
    "                  error_kw=dict(ecolor='black', elinewidth=2))\n",
    "\n",
    "ax_bar.set_ylabel('Ripple rate by trial (Hz)')\n",
    "ax_bar.set_xlabel('')\n",
    "ax_bar.set_ylim(bar_ylimits)\n",
    "ax_bar.set_xticklabels(['Clustered', 'Unclustered', 'Not Recalled'], rotation=20, ha=\"center\")\n",
    "ax_bar.spines['right'].set_visible(False)\n",
    "ax_bar.spines['top'].set_visible(False)\n",
    "ax_bar.set_title('no low gamma trials')\n",
    "\n",
    "# Add the number of trials above each bar\n",
    "n_trials = [np.sum(trial_select & clust_clustered), \n",
    "            np.sum(trial_select & clust_unclustered), \n",
    "            np.sum(trial_select & clust_not_recalled)]\n",
    "for bar, n in zip(bars, n_trials):\n",
    "    ax_bar.text(bar.get_x() + bar.get_width() / 2, bar.get_height() + 0.01, f'n={n}', ha='center', va='bottom')\n",
    "\n",
    "# Calculate PSTH for each group\n",
    "ripple_PSTH_clustered, bin_centers = fullPSTH(start_array[trial_select & clust_clustered], bin_size, smoothing_triangle, fs, ripple_start_offset)\n",
    "ripple_PSTH_unclustered, _ = fullPSTH(start_array[trial_select & clust_unclustered], bin_size, smoothing_triangle, fs, ripple_start_offset)\n",
    "ripple_PSTH_not_recalled, _ = fullPSTH(start_array[trial_select & clust_not_recalled], bin_size, smoothing_triangle, fs, ripple_start_offset)\n",
    "\n",
    "# Plot the PSTH for each group\n",
    "ax_psth = fig.add_subplot(gs[1, :])\n",
    "ax_psth.plot(bin_centers / 1000, ripple_PSTH_clustered, label='Clustered', color=palette['Clustered'])\n",
    "ax_psth.plot(bin_centers / 1000, ripple_PSTH_unclustered, label='Unclustered', color=palette['Unclustered'])\n",
    "if encoding_mode == 1:\n",
    "    ax_psth.plot(bin_centers / 1000, ripple_PSTH_not_recalled, label='Not Recalled', color=palette['Not Recalled'])\n",
    "    ax_psth.axvline(x=0.0, color='black', linestyle='--')\n",
    "    ax_psth.axvline(x=1.6, color='black', linestyle='--')\n",
    "    ax_psth.set_xlim(-0.25, 2.05)\n",
    "elif encoding_mode == 0:\n",
    "    ax_psth.set_xlim(-2.0, 2.0)\n",
    "ax_psth.set_xlabel('Time (s)')\n",
    "ax_psth.set_ylim(0,bar_ylimits[1])\n",
    "ax_psth.set_ylabel('Ripple rate (Hz)')\n",
    "ax_psth.spines['right'].set_visible(False)\n",
    "ax_psth.spines['top'].set_visible(False)\n",
    "\n",
    "# Add legend to the bottom plot\n",
    "ax_psth.legend(loc='lower center', frameon=False)\n",
    "\n",
    "# Adjust layout\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "a=1;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0d5a8dd-f8a3-40c0-b6a6-a20c2ca89bd7",
   "metadata": {},
   "source": [
    "# ripples only for + low gamma trials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc797628-58bb-4e9b-8f50-39c2c5ed2d2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function parameters\n",
    "bin_size = 100  # in ms\n",
    "smoothing_triangle = 5  # triangular smoothing window width\n",
    "\n",
    "bar_ylimits = (0, 0.72)\n",
    "\n",
    "if remove_low_freq == 1:\n",
    "    trial_select = z_low_gamma_trials\n",
    "elif remove_low_freq == 2:\n",
    "    trial_select = z_high_gamma_trials\n",
    "else:\n",
    "    print('Invalid remove_low_freq selection')\n",
    "    error\n",
    "\n",
    "ripple_swarm_start = int((-ripple_start_offset+ripple_analysis_start)/sr_factor)\n",
    "ripple_swarm_end = int((-ripple_start_offset+ripple_analysis_end)/sr_factor)\n",
    "ripple_swarm_duration = (ripple_analysis_end-ripple_analysis_start)/1000  # convert to seconds\n",
    "\n",
    "# Apply the clust variable to split data into clustered, unclustered, and not recalled\n",
    "clust_clustered = sub_clust_ID > 1\n",
    "clust_unclustered = sub_clust_ID < 0\n",
    "clust_not_recalled = sub_clust_ID == 0\n",
    "\n",
    "# Calculate ripple means and standard errors for each condition\n",
    "mean_ripple_clustered = np.sum(start_array[trial_select & clust_clustered, ripple_swarm_start:ripple_swarm_end], axis=1) / ripple_swarm_duration\n",
    "mean_ripple_unclustered = np.sum(start_array[trial_select & clust_unclustered, ripple_swarm_start:ripple_swarm_end], axis=1) / ripple_swarm_duration\n",
    "mean_ripple_not_recalled = np.sum(start_array[trial_select & clust_not_recalled, ripple_swarm_start:ripple_swarm_end], axis=1) / ripple_swarm_duration\n",
    "\n",
    "if encoding_mode == 1:\n",
    "    means = [np.mean(mean_ripple_clustered), np.mean(mean_ripple_unclustered), np.mean(mean_ripple_not_recalled)]\n",
    "    ses = [np.std(mean_ripple_clustered) / np.sqrt(len(mean_ripple_clustered)),\n",
    "           np.std(mean_ripple_unclustered) / np.sqrt(len(mean_ripple_unclustered)),\n",
    "           np.std(mean_ripple_not_recalled) / np.sqrt(len(mean_ripple_not_recalled))]\n",
    "    fig = plt.figure(figsize=(4, 5))\n",
    "elif encoding_mode == 0:\n",
    "    means = [np.mean(mean_ripple_clustered), np.mean(mean_ripple_unclustered)]\n",
    "    ses = [np.std(mean_ripple_clustered) / np.sqrt(len(mean_ripple_clustered)),\n",
    "           np.std(mean_ripple_unclustered) / np.sqrt(len(mean_ripple_unclustered))]    \n",
    "    fig = plt.figure(figsize=(3, 5))\n",
    "\n",
    "# Define the palette for colors\n",
    "palette = {\n",
    "    'Clustered': 'blue',\n",
    "    'Unclustered': 'orange',\n",
    "    'Not Recalled': 'green'\n",
    "}\n",
    "\n",
    "# Set up the figure with GridSpec\n",
    "gs = gridspec.GridSpec(2, 3, height_ratios=[2, 2], width_ratios=[3, 3, 3])\n",
    "\n",
    "# Create the bar plot with error bars (span all columns)\n",
    "ax_bar = fig.add_subplot(gs[0, :])\n",
    "if encoding_mode == 1:\n",
    "    xlabels = ['Clustered', 'Unclustered', 'Not Recalled']\n",
    "    xcolors = [palette['Clustered'], palette['Unclustered'], palette['Not Recalled']]\n",
    "elif encoding_mode == 0:\n",
    "    xlabels = ['Clustered', 'Unclustered']\n",
    "    xcolors = [palette['Clustered'], palette['Unclustered']]\n",
    "bars = ax_bar.bar(x=xlabels, \n",
    "                  height=means, \n",
    "                  color=xcolors, \n",
    "                  yerr=ses, \n",
    "                  width=0.5,  # Adjust width to make bars tighter\n",
    "                  capsize=5, \n",
    "                  error_kw=dict(ecolor='black', elinewidth=2))\n",
    "\n",
    "ax_bar.set_ylabel('Ripple rate by trial (Hz)')\n",
    "ax_bar.set_xlabel('')\n",
    "ax_bar.set_ylim(bar_ylimits)\n",
    "ax_bar.set_xticklabels(xlabels, rotation=20, ha=\"center\")\n",
    "ax_bar.spines['right'].set_visible(False)\n",
    "ax_bar.spines['top'].set_visible(False)\n",
    "ax_bar.set_title('only low gamma trials')\n",
    "\n",
    "# Add the number of trials above each bar\n",
    "n_trials = [np.sum(trial_select & clust_clustered), \n",
    "            np.sum(trial_select & clust_unclustered), \n",
    "            np.sum(trial_select & clust_not_recalled)]\n",
    "for bar, n in zip(bars, n_trials):\n",
    "    ax_bar.text(bar.get_x() + bar.get_width() / 2, bar.get_height() + 0.03, f'n={n}', ha='center', va='bottom')\n",
    "\n",
    "# Calculate PSTH for each group\n",
    "ripple_PSTH_clustered, bin_centers = fullPSTH(start_array[trial_select & clust_clustered], bin_size, smoothing_triangle, fs, ripple_start_offset)\n",
    "ripple_PSTH_unclustered, _ = fullPSTH(start_array[trial_select & clust_unclustered], bin_size, smoothing_triangle, fs, ripple_start_offset)\n",
    "ripple_PSTH_not_recalled, _ = fullPSTH(start_array[trial_select & clust_not_recalled], bin_size, smoothing_triangle, fs, ripple_start_offset)\n",
    "\n",
    "# Plot the PSTH for each group\n",
    "ax_psth = fig.add_subplot(gs[1, :])\n",
    "ax_psth.plot(bin_centers / 1000, ripple_PSTH_clustered, label='Clustered', color=palette['Clustered'])\n",
    "ax_psth.plot(bin_centers / 1000, ripple_PSTH_unclustered, label='Unclustered', color=palette['Unclustered'])\n",
    "if encoding_mode == 1:\n",
    "    ax_psth.plot(bin_centers / 1000, ripple_PSTH_not_recalled, label='Not Recalled', color=palette['Not Recalled'])\n",
    "    ax_psth.axvline(x=0.0, color='black', linestyle='--')\n",
    "    ax_psth.axvline(x=1.6, color='black', linestyle='--')\n",
    "    ax_psth.set_xlim(-0.25, 2.05)\n",
    "elif encoding_mode == 0:\n",
    "    ax_psth.set_xlim(-2.0, 2.0)\n",
    "ax_psth.set_xlabel('Time (s)')\n",
    "ax_psth.set_ylim(0,bar_ylimits[1])\n",
    "ax_psth.set_ylabel('Ripple rate (Hz)')\n",
    "ax_psth.spines['right'].set_visible(False)\n",
    "ax_psth.spines['top'].set_visible(False)\n",
    "\n",
    "# Add legend to the bottom plot\n",
    "ax_psth.legend(loc='lower center', frameon=False)\n",
    "\n",
    "# Adjust layout\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "a=1;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1f31b99-b050-4760-9327-ee4cad3d6c4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels.api as sm\n",
    "from statsmodels.formula.api import mixedlm\n",
    "\n",
    "# Flatten the ripple data for easier modeling\n",
    "ripple_data = start_array[:, ripple_swarm_start:ripple_swarm_end].sum(axis=1)\n",
    "\n",
    "# Create a DataFrame with the data\n",
    "df = pd.DataFrame({\n",
    "    'ripple_rate': ripple_data,\n",
    "    'clust_clustered': (sub_clust_ID > 1).astype(int),\n",
    "    'clust_unclustered': (sub_clust_ID < 0).astype(int),\n",
    "    'clust_not_recalled': (sub_clust_ID == 0).astype(int),\n",
    "    'session': dd_trials['sess'][final_sub_idxs],\n",
    "    'subject': dd_trials['subj'][final_sub_idxs],\n",
    "    'low_gamma': z_low_gamma_trials,\n",
    "})\n",
    "if remove_low_freq == 2:\n",
    "    df['high_gamma'] = z_high_gamma_trials\n",
    "\n",
    "# Define the model formula\n",
    "# 'ripple_rate ~ clust_clustered + clust_unclustered + clust_not_recalled' specifies the fixed effects\n",
    "# '(1 | subject/session)' specifies the random effects, with session nested within subject\n",
    "if encoding_mode == 1:\n",
    "    formula = \"ripple_rate ~ clust_clustered + clust_unclustered\"\n",
    "elif encoding_mode == 0:\n",
    "    formula = \"ripple_rate ~ clust_clustered\" # since not recalled doesn't exist\n",
    "model = mixedlm(\n",
    "    formula=formula,data=df, groups=df[\"subject\"], vc_formula={\"session\": \"0 + session\"})\n",
    "\n",
    "print(model.fit().summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b575e2f8-aedc-408b-868a-59d37214aff4",
   "metadata": {},
   "outputs": [],
   "source": [
    "if encoding_mode == 1:\n",
    "    if remove_low_freq == 1:\n",
    "        formula = \"ripple_rate ~ low_gamma*(clust_clustered + clust_unclustered)\"\n",
    "    elif remove_low_freq == 2:\n",
    "        formula = \"ripple_rate ~ high_gamma*(clust_clustered + clust_unclustered)\"\n",
    "elif encoding_mode == 0:\n",
    "    if remove_low_freq == 1:\n",
    "        formula = \"ripple_rate ~ low_gamma*clust_clustered\" # since not recalled doesn't exist\n",
    "    elif remove_low_freq == 2:\n",
    "        formula = \"ripple_rate ~ high_gamma*clust_clustered\" # since not recalled doesn't exist\n",
    "model = mixedlm(\n",
    "    formula=formula,data=df, groups=df[\"subject\"], vc_formula={\"session\": \"0 + session\"})\n",
    "\n",
    "print(model.fit().summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23c20a39-afb1-4310-bf8f-fd18f940ed94",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bdb39c1-2633-4f75-a9f3-914dafaaf7a5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "workshopJ",
   "language": "python",
   "name": "workshopj"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
